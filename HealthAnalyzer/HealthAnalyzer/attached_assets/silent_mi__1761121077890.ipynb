{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===== CLEAN SETUP FOR COLAB =====\n",
        "# Uninstall noisy packages that force incompatible deps\n",
        "%pip -q uninstall -y tensorflow-text tf-keras tensorflow-decision-forests ydf jax pytensor umap-learn opentelemetry-proto opencv-contrib-python opencv-python-headless || true\n",
        "\n",
        "# Minimal, compatible stack for our ECG model\n",
        "%pip -q install \\\n",
        "  tensorflow==2.16.1 \\\n",
        "  protobuf==4.25.3 \\\n",
        "  numpy==1.26.4 \\\n",
        "  scipy==1.13.1 \\\n",
        "  scikit-learn==1.5.2 \\\n",
        "  pandas==2.2.2 \\\n",
        "  matplotlib==3.9.0 \\\n",
        "  wfdb==4.1.2 \\\n",
        "  requests==2.32.3 \\\n",
        "  tqdm==4.66.4\n",
        "\n",
        "import platform, tensorflow as tf, numpy as np, pandas as pd, scipy, sklearn, wfdb\n",
        "print(\"✅ Setup complete\")\n",
        "print(\"Python:\", platform.python_version())\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"pandas:\", pd.__version__)\n",
        "print(\"SciPy:\", scipy.__version__)\n",
        "print(\"scikit-learn:\", sklearn.__version__)\n",
        "print(\"WFDB:\", wfdb.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmS2K4kDmDQ3",
        "outputId": "2a547373-c3b6-45bf-e71c-1e727bfb2911"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-text as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tf-keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-decision-forests as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping ydf as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping jax as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping pytensor as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping umap-learn as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opentelemetry-proto as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-contrib-python as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.3 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.4 which is incompatible.\n",
            "google-adk 1.16.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m✅ Setup complete\n",
            "Python: 3.12.12\n",
            "TensorFlow: 2.19.0\n",
            "NumPy: 2.0.2\n",
            "pandas: 2.2.2\n",
            "SciPy: 1.16.2\n",
            "scikit-learn: 1.6.1\n",
            "WFDB: 4.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Small compat patch to align with Colab’s pinned deps\n",
        "%pip -q install -U requests==2.32.4 tqdm==4.67.1 protobuf==5.26.1\n",
        "import requests, tqdm, google\n",
        "print(\"requests:\", requests.__version__)\n",
        "import importlib, pkgutil\n",
        "print(\"✅ Patched. Continue with your pipeline cell.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDiNmyPfkVmL",
        "outputId": "36112b62-e602-495f-b441-26ece5247dec"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires jax>=0.1.72, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, which is not installed.\n",
            "tensorflow-hub 0.16.1 requires tf-keras>=2.14.1, which is not installed.\n",
            "orbax-checkpoint 0.11.24 requires jax>=0.5.0, which is not installed.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, which is not installed.\n",
            "tensorflow 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mrequests: 2.32.4\n",
            "✅ Patched. Continue with your pipeline cell.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== SILENT MI / ACUTE MI PREDICTOR (PTB-XL) — FULL PIPELINE =====\n",
        "\n",
        "import os, ast, json, re, math, random, warnings, time\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "import requests, wfdb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# -------------------------\n",
        "# 0) Config / constants\n",
        "# -------------------------\n",
        "BASE = Path(\"/content\")\n",
        "PTBXL_DB = BASE / \"ptbxl_database.csv\"\n",
        "SCP_CSV  = BASE / \"scp_statements.csv\"\n",
        "RECORDS  = BASE / \"RECORDS\"        # text file with stems like: records500/00000/00001\n",
        "PHYSIONET_BASE = \"https://physionet.org/files/ptb-xl/1.0.3\"  # official source\n",
        "\n",
        "IMG_SIZE = (224, 224)   # (unused for this CNN, kept for reference)\n",
        "BATCH    = 32\n",
        "EPOCHS   = 20\n",
        "SEED     = 42\n",
        "TARGET_LEN = 1000       # 10 seconds at 100 Hz for PTB-XL low-res\n",
        "\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
        "\n",
        "# Sanity: check your uploads\n",
        "assert PTBXL_DB.exists(), \"Missing ptbxl_database.csv in /content\"\n",
        "assert SCP_CSV.exists(),  \"Missing scp_statements.csv in /content\"\n",
        "assert RECORDS.exists(),  \"Missing RECORDS file in /content\"\n",
        "\n",
        "# --------------------------------------\n",
        "# 1) Load CSVs + restrict to your RECORDS\n",
        "# --------------------------------------\n",
        "df  = pd.read_csv(PTBXL_DB)\n",
        "scp = pd.read_csv(SCP_CSV, index_col=0)\n",
        "\n",
        "def parse_present_codes(s):\n",
        "    try:\n",
        "        d = ast.literal_eval(s) if isinstance(s, str) else (s if isinstance(s, dict) else {})\n",
        "    except Exception:\n",
        "        d = {}\n",
        "    # keep keys with nonzero weight\n",
        "    return [k for k, v in d.items() if float(v) > 0.0]\n",
        "\n",
        "df[\"labels_all\"] = df[\"scp_codes\"].apply(parse_present_codes)\n",
        "# rec_key should be the WFDB stem (no extension). Use filename_lr without .mat if present, else filename_hr.\n",
        "if \"filename_lr\" in df.columns:\n",
        "    df[\"rec_key\"] = df[\"filename_lr\"].str.replace(\".mat\", \"\", regex=False)\n",
        "else:\n",
        "    df[\"rec_key\"] = df[\"filename_hr\"].str.replace(\".mat\", \"\", regex=False)\n",
        "\n",
        "# Load RECORDS list (stems). Accept both with and without extension lines.\n",
        "with open(RECORDS, \"r\") as f:\n",
        "    rec_list = []\n",
        "    for ln in f:\n",
        "        s = ln.strip()\n",
        "        if not s: continue\n",
        "        s = s.replace(\".mat\",\"\").replace(\".dat\",\"\").replace(\".hea\",\"\")\n",
        "        rec_list.append(s)\n",
        "rec_set = set(rec_list)\n",
        "\n",
        "# --- Normalize RECORDS lines to valid PTB-XL stems ---\n",
        "norm_list = []\n",
        "for s in rec_list:\n",
        "    s = s.replace(\".mat\",\"\").replace(\".dat\",\"\").replace(\".hea\",\"\")\n",
        "    # If lines start with \"records/\" instead of \"records500/\" or \"records100/\",\n",
        "    # convert automatically to \"records500/\" (for low-resolution 100 Hz signals)\n",
        "    if s.startswith(\"records/\"):\n",
        "        s = s.replace(\"records/\", \"records500/\", 1)\n",
        "    norm_list.append(s)\n",
        "\n",
        "rec_set = set(norm_list)\n",
        "\n",
        "# Apply to dataframe\n",
        "df = df[df[\"rec_key\"].isin(rec_set)].reset_index(drop=True)\n",
        "print(f\"Matched {len(df)} rows to normalized RECORDS.\")\n",
        "\n",
        "\n",
        "df = df[df[\"rec_key\"].isin(rec_set)].reset_index(drop=True)\n",
        "print(f\"Matched {len(df)} rows to RECORDS.\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 2) Fetch WFDB files (.dat/.hea) if missing\n",
        "# --------------------------------------\n",
        "def ensure_local_record(rec_key: str, root=\"/content\", retries=3, timeout=60):\n",
        "    \"\"\"\n",
        "    Ensures /content/<rec_key>.dat and .hea exist; downloads from PhysioNet if missing.\n",
        "    \"\"\"\n",
        "    dat = os.path.join(root, rec_key + \".dat\")\n",
        "    hea = os.path.join(root, rec_key + \".hea\")\n",
        "    if os.path.isfile(dat) and os.path.isfile(hea):\n",
        "        return True\n",
        "\n",
        "    # Make dirs\n",
        "    os.makedirs(os.path.dirname(dat), exist_ok=True)\n",
        "\n",
        "    for ext in [\".dat\", \".hea\"]:\n",
        "        out = os.path.join(root, rec_key + ext)\n",
        "        if os.path.isfile(out):\n",
        "            continue\n",
        "        url = f\"{PHYSIONET_BASE}/{rec_key}{ext}\"\n",
        "        ok = False\n",
        "        for attempt in range(1, retries+1):\n",
        "            try:\n",
        "                r = requests.get(url, timeout=timeout)\n",
        "                r.raise_for_status()\n",
        "                with open(out, \"wb\") as fp:\n",
        "                    fp.write(r.content)\n",
        "                ok = True\n",
        "                break\n",
        "            except Exception as e:\n",
        "                if attempt == retries:\n",
        "                    print(f\"❌ Failed to fetch {url}: {e}\")\n",
        "                time.sleep(1.0)\n",
        "        if not ok:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "print(\"Checking/downloading WFDB records (this may take a while on first run)...\")\n",
        "fail_ct = 0\n",
        "for rk in tqdm(df[\"rec_key\"].tolist()):\n",
        "    if not ensure_local_record(rk):\n",
        "        fail_ct += 1\n",
        "print(\"Download failures:\", fail_ct)\n",
        "\n",
        "# --------------------------------------\n",
        "# 3) Make 3-class labels: Normal / Silent_MI / Acute_MI\n",
        "# --------------------------------------\n",
        "def _norm(s): return str(s).lower() if isinstance(s, str) else \"\"\n",
        "\n",
        "def _get_col(dfcols, options):\n",
        "    low = {c.lower(): c for c in dfcols}\n",
        "    for opt in options:\n",
        "        if opt in low: return low[opt]\n",
        "    return None\n",
        "\n",
        "col_diag_class = _get_col(scp.columns, [\"diagnostic_class\",\"class\",\"superclass\"])\n",
        "col_description = _get_col(scp.columns, [\"description\",\"diagnostic\",\"detailed_description\",\"full_description\"])\n",
        "has_desc = col_description is not None\n",
        "\n",
        "ACUTE_TOKENS = [\"acute\", \"stemi\", \"nstemi\", \"ami\", \"acute myocardial\"]\n",
        "SILENT_HINTS = [\"old\", \"previous\", \"healed\", \"scar\"]\n",
        "\n",
        "def classify_mi_codes(code_list):\n",
        "    if not code_list: return None\n",
        "    acute = False\n",
        "    mi_present = False\n",
        "    for code in code_list:\n",
        "        if code not in scp.index: continue\n",
        "        row = scp.loc[code]\n",
        "        diag_class = _norm(row.get(col_diag_class, \"\"))\n",
        "        if diag_class == \"mi\":\n",
        "            mi_present = True\n",
        "            desc = _norm(row.get(col_description, \"\")) if has_desc else \"\"\n",
        "            if any(tok in desc for tok in ACUTE_TOKENS) or any(tok in _norm(code) for tok in ACUTE_TOKENS):\n",
        "                acute = True\n",
        "            if code.upper() in [\"AMI\",\"STEMI\",\"NSTEMI\"]:\n",
        "                acute = True\n",
        "    if mi_present:\n",
        "        return \"Acute_MI\" if acute else \"Silent_MI\"\n",
        "    return None\n",
        "\n",
        "def parse_scp_dict(s):\n",
        "    try:\n",
        "        return ast.literal_eval(s) if isinstance(s, str) else (s if isinstance(s, dict) else {})\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "df[\"scp_codes_dict\"] = df[\"scp_codes\"].apply(parse_scp_dict)\n",
        "\n",
        "labels = []\n",
        "for _, r in df.iterrows():\n",
        "    codes = list(r[\"scp_codes_dict\"].keys())\n",
        "    mi = classify_mi_codes(codes)\n",
        "    if mi is not None:\n",
        "        labels.append(mi)\n",
        "    else:\n",
        "        dclass = r.get(\"diagnostic_class\", \"\")\n",
        "        if isinstance(dclass, str) and dclass.upper() == \"NORM\":\n",
        "            labels.append(\"Normal\")\n",
        "        else:\n",
        "            labels.append(\"Other\")\n",
        "\n",
        "df[\"target3\"] = labels\n",
        "df3 = df[df[\"target3\"].isin([\"Normal\",\"Silent_MI\",\"Acute_MI\"])].reset_index(drop=True)\n",
        "print(\"Label counts (filtered to our 3 classes):\")\n",
        "print(df3[\"target3\"].value_counts())\n",
        "\n",
        "# --------------------------------------\n",
        "# 4) Load WFDB signals for rec_key stems\n",
        "# --------------------------------------\n",
        "def center_pad_or_truncate(x, tgt=TARGET_LEN):\n",
        "    T = x.shape[1]\n",
        "    if T == tgt: return x\n",
        "    if T > tgt:\n",
        "        start = (T - tgt)//2\n",
        "        return x[:, start:start+tgt]\n",
        "    pad = tgt - T\n",
        "    left = pad//2\n",
        "    right = pad - left\n",
        "    return np.pad(x, ((0,0),(left,right)), mode=\"constant\", constant_values=0.0)\n",
        "\n",
        "def load_wfdb_by_rec_key(rec_key: str, root=\"/content\"):\n",
        "    stem = os.path.join(root, rec_key)\n",
        "    sig, meta = wfdb.rdsamp(stem)  # (T, n_leads) floats\n",
        "    sig = sig.T.astype(np.float32) # (12, T)\n",
        "    return sig\n",
        "\n",
        "def sex_to_num(s):\n",
        "    s = str(s).strip().lower()\n",
        "    if s.startswith(\"m\"): return 1\n",
        "    if s.startswith(\"f\"): return 0\n",
        "    try:\n",
        "        v = float(s); return 1 if v > 0.5 else 0\n",
        "    except: return 0\n",
        "\n",
        "print(\"\\nLoading ECGs...\")\n",
        "ecgs, demos, ys = [], [], []\n",
        "missing = 0\n",
        "CLASSES = [\"Normal\",\"Silent_MI\",\"Acute_MI\"]\n",
        "class_to_id = {c:i for i,c in enumerate(CLASSES)}\n",
        "\n",
        "for _, r in tqdm(df3.iterrows(), total=len(df3)):\n",
        "    rk = r[\"rec_key\"]\n",
        "    dat = BASE / f\"{rk}.dat\"\n",
        "    hea = BASE / f\"{rk}.hea\"\n",
        "    if not (dat.exists() and hea.exists()):\n",
        "        missing += 1\n",
        "        continue\n",
        "    try:\n",
        "        sig = load_wfdb_by_rec_key(rk)  # (12, T)\n",
        "        if sig.shape[0] != 12: continue\n",
        "        sig = center_pad_or_truncate(sig, TARGET_LEN)\n",
        "        # robust per-lead z-norm\n",
        "        mu = np.median(sig, axis=1, keepdims=True)\n",
        "        sd = np.std(sig, axis=1, keepdims=True) + 1e-6\n",
        "        sig = (sig - mu) / sd\n",
        "        ecgs.append(sig[..., None])  # (12, T, 1)\n",
        "\n",
        "        # demographics\n",
        "        age = float(r.get(\"age\", np.nan))\n",
        "        if not (0 < age < 120): age = np.nan\n",
        "        sx = sex_to_num(r.get(\"sex\",\"\"))\n",
        "        demos.append([0.0 if np.isnan(age) else age, sx])\n",
        "\n",
        "        ys.append(class_to_id[r[\"target3\"]])\n",
        "    except Exception:\n",
        "        continue\n",
        "\n",
        "X_ecg = np.asarray(ecgs, dtype=np.float32)\n",
        "X_demo = np.asarray(demos, dtype=np.float32)\n",
        "y = np.asarray(ys, dtype=np.int64)\n",
        "\n",
        "print(f\"Loaded {len(y)} samples. (Skipped {missing} missing/unreadable.)\")\n",
        "if len(y) == 0:\n",
        "    raise RuntimeError(\"No ECGs loaded. Verify the download step completed and paths like /content/records500/00000/00001.(dat|hea) exist.\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 5) Split\n",
        "# --------------------------------------\n",
        "X_e_train, X_e_tmp, X_d_train, X_d_tmp, y_train, y_tmp = train_test_split(\n",
        "    X_ecg, X_demo, y, test_size=0.30, random_state=SEED, stratify=y\n",
        ")\n",
        "X_e_val, X_e_test, X_d_val, X_d_test, y_val, y_test = train_test_split(\n",
        "    X_e_tmp, X_d_tmp, y_tmp, test_size=0.50, random_state=SEED, stratify=y_tmp\n",
        ")\n",
        "\n",
        "# --------------------------------------\n",
        "# 6) Model: 2D CNN over (leads x time) + demographic branch\n",
        "# --------------------------------------\n",
        "def build_model(time_len=TARGET_LEN, n_leads=12, n_classes=3):\n",
        "    ecg_in = keras.Input(shape=(n_leads, time_len, 1), name=\"ecg\")\n",
        "    x = layers.Conv2D(16, (3,7), strides=(1,2), padding=\"same\")(ecg_in)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool2D(pool_size=(1,2))(x)\n",
        "\n",
        "    x = layers.Conv2D(32, (3,7), strides=(1,2), padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.MaxPool2D(pool_size=(1,2))(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3,7), strides=(1,2), padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x); x = layers.ReLU()(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    demo_in = keras.Input(shape=(2,), name=\"demo\")  # [age, sex]\n",
        "    norm = layers.Normalization()\n",
        "    d = norm(demo_in)\n",
        "    d = layers.Dense(16, activation=\"relu\")(d)\n",
        "\n",
        "    h = layers.Concatenate()([x, d])\n",
        "    h = layers.Dense(64, activation=\"relu\")(h)\n",
        "    h = layers.Dropout(0.3)(h)\n",
        "    out = layers.Dense(n_classes, activation=\"softmax\")(h)\n",
        "\n",
        "    model = keras.Model(inputs=[ecg_in, demo_in], outputs=out)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model, norm\n",
        "\n",
        "model, demo_norm = build_model()\n",
        "demo_norm.adapt(X_d_train)\n",
        "\n",
        "# --------------------------------------\n",
        "# Class weights for imbalance (robust)\n",
        "# --------------------------------------\n",
        "from collections import Counter\n",
        "train_counts = Counter(y_train)\n",
        "print(\"Train label counts:\", train_counts, \" (0=Normal, 1=Silent_MI, 2=Acute_MI)\")\n",
        "\n",
        "present = np.unique(y_train)\n",
        "\n",
        "if len(present) >= 2:\n",
        "    # Compute weights only for classes that actually appear in y_train\n",
        "    cw = compute_class_weight(\n",
        "        class_weight=\"balanced\",\n",
        "        classes=present,\n",
        "        y=y_train\n",
        "    )\n",
        "    class_weights = {int(c): float(w) for c, w in zip(present, cw)}\n",
        "    # (Optional) give missing classes the max weight, so if they appear in val/test they aren't ignored\n",
        "    maxw = max(class_weights.values())\n",
        "    for c in [0, 1, 2]:\n",
        "        class_weights.setdefault(c, maxw)\n",
        "else:\n",
        "    # Degenerate case: only one label in training\n",
        "    print(\"⚠️ Only one class present in y_train; disabling class weights.\")\n",
        "    class_weights = None\n",
        "\n",
        "print(\"Class weights used:\", class_weights)\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# 7) Train\n",
        "# --------------------------------------\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    {\"ecg\": X_e_train, \"demo\": X_d_train},\n",
        "    y_train,\n",
        "    validation_data=({\"ecg\": X_e_val, \"demo\": X_d_val}, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI5lTt-ilUtC",
        "outputId": "f14738e2-13a1-4739-fb1c-f3973fcd9c1f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matched 21798 rows to normalized RECORDS.\n",
            "Matched 21798 rows to RECORDS.\n",
            "Checking/downloading WFDB records (this may take a while on first run)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21798/21798 [00:00<00:00, 118755.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download failures: 0\n",
            "Label counts (filtered to our 3 classes):\n",
            "target3\n",
            "Silent_MI    5116\n",
            "Acute_MI      353\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Loading ECGs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5469/5469 [00:18<00:00, 288.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5469 samples. (Skipped 0 missing/unreadable.)\n",
            "Train label counts: Counter({np.int64(1): 3581, np.int64(2): 247})  (0=Normal, 1=Silent_MI, 2=Acute_MI)\n",
            "Class weights used: {1: 0.5344875733035465, 2: 7.748987854251012, 0: 7.748987854251012}\n",
            "Epoch 1/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 369ms/step - accuracy: 0.4777 - loss: 0.7971 - val_accuracy: 0.7659 - val_loss: 0.6199\n",
            "Epoch 2/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 358ms/step - accuracy: 0.6703 - loss: 0.6786 - val_accuracy: 0.8524 - val_loss: 0.4942\n",
            "Epoch 3/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 360ms/step - accuracy: 0.7149 - loss: 0.6286 - val_accuracy: 0.3841 - val_loss: 0.8936\n",
            "Epoch 4/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 358ms/step - accuracy: 0.7240 - loss: 0.6117 - val_accuracy: 0.1488 - val_loss: 1.3613\n",
            "Epoch 5/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 352ms/step - accuracy: 0.7533 - loss: 0.5899 - val_accuracy: 0.2427 - val_loss: 1.3446\n",
            "Epoch 6/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 358ms/step - accuracy: 0.7537 - loss: 0.5745 - val_accuracy: 0.2829 - val_loss: 1.1606\n",
            "Epoch 7/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 387ms/step - accuracy: 0.7590 - loss: 0.5415 - val_accuracy: 0.4280 - val_loss: 0.9439\n",
            "Epoch 8/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 351ms/step - accuracy: 0.7720 - loss: 0.5112 - val_accuracy: 0.4220 - val_loss: 1.0117\n",
            "Epoch 9/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 360ms/step - accuracy: 0.7932 - loss: 0.4837 - val_accuracy: 0.3890 - val_loss: 1.1032\n",
            "Epoch 10/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 360ms/step - accuracy: 0.7892 - loss: 0.4768 - val_accuracy: 0.3951 - val_loss: 1.0412\n",
            "Epoch 11/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 364ms/step - accuracy: 0.8059 - loss: 0.4365 - val_accuracy: 0.6146 - val_loss: 0.7139\n",
            "Epoch 12/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 353ms/step - accuracy: 0.8119 - loss: 0.4114 - val_accuracy: 0.6976 - val_loss: 0.5294\n",
            "Epoch 13/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 351ms/step - accuracy: 0.8071 - loss: 0.4078 - val_accuracy: 0.7976 - val_loss: 0.4125\n",
            "Epoch 14/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 358ms/step - accuracy: 0.8138 - loss: 0.4048 - val_accuracy: 0.5890 - val_loss: 0.9844\n",
            "Epoch 15/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 359ms/step - accuracy: 0.8397 - loss: 0.3423 - val_accuracy: 0.9293 - val_loss: 0.2535\n",
            "Epoch 16/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 364ms/step - accuracy: 0.8479 - loss: 0.3294 - val_accuracy: 0.3671 - val_loss: 1.2145\n",
            "Epoch 17/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 362ms/step - accuracy: 0.8689 - loss: 0.2892 - val_accuracy: 0.5841 - val_loss: 0.8900\n",
            "Epoch 18/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 357ms/step - accuracy: 0.8618 - loss: 0.2918 - val_accuracy: 0.2037 - val_loss: 2.9840\n",
            "Epoch 19/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 391ms/step - accuracy: 0.8864 - loss: 0.2496 - val_accuracy: 0.3780 - val_loss: 1.5414\n",
            "Epoch 20/20\n",
            "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 363ms/step - accuracy: 0.8777 - loss: 0.2570 - val_accuracy: 0.4756 - val_loss: 1.3863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --------------------------------------\n",
        "# 8) Evaluate + Save  (robust to missing classes in test)\n",
        "# --------------------------------------\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Predict\n",
        "probs = model.predict({\"ecg\": X_e_test, \"demo\": X_d_test}, batch_size=128, verbose=0)\n",
        "preds = probs.argmax(axis=1)\n",
        "\n",
        "# Figure out which classes are actually present in y_test\n",
        "labels_present = np.unique(y_test)\n",
        "name_map = {0: \"Normal\", 1: \"Silent_MI\", 2: \"Acute_MI\"}\n",
        "names_present = [name_map[i] for i in labels_present]\n",
        "\n",
        "print(\"\\nTest Classification Report (only classes present in y_test):\")\n",
        "print(classification_report(\n",
        "    y_test, preds,\n",
        "    labels=labels_present,\n",
        "    target_names=names_present,\n",
        "    digits=4,\n",
        "    zero_division=0\n",
        "))\n",
        "\n",
        "print(\"Confusion Matrix (only present classes, in this order):\", names_present)\n",
        "print(confusion_matrix(y_test, preds, labels=labels_present))\n",
        "\n",
        "# (Optional) Also show calibrated overall accuracy and per-class support\n",
        "acc = (preds == y_test).mean() if len(y_test) else float('nan')\n",
        "supports = {name_map[i]: int((y_test==i).sum()) for i in labels_present}\n",
        "print(f\"\\nOverall accuracy: {acc:.4f}\")\n",
        "print(\"Supports:\", supports)\n",
        "\n",
        "# Save model\n",
        "MODEL_PATH = str(BASE / \"silent_mi_cnn_wfdb.h5\")\n",
        "model.save(MODEL_PATH)\n",
        "print(f\"\\nModel saved to: {MODEL_PATH}\")\n",
        "\n",
        "# --------------------------------------\n",
        "# 9) One-off prediction helper\n",
        "# --------------------------------------\n",
        "def predict_single_rec(rec_key: str, age: float, sex_str: str, root=\"/content\"):\n",
        "    \"\"\"\n",
        "    rec_key example: 'records500/00000/00001' (stem w/o extension).\n",
        "    \"\"\"\n",
        "    dat = Path(root) / f\"{rec_key}.dat\"\n",
        "    hea = Path(root) / f\"{rec_key}.hea\"\n",
        "    assert dat.exists() and hea.exists(), f\"Missing WFDB files for {rec_key} under {root}\"\n",
        "\n",
        "    sig, _ = wfdb.rdsamp(os.path.join(root, rec_key))\n",
        "    sig = sig.T.astype(np.float32)\n",
        "    sig = center_pad_or_truncate(sig, TARGET_LEN)\n",
        "    sig = (sig - np.median(sig, axis=1, keepdims=True)) / (np.std(sig, axis=1, keepdims=True) + 1e-6)\n",
        "\n",
        "    x_ecg = sig[np.newaxis, ..., None]                     # (1, 12, T, 1)\n",
        "    x_demo = np.array([[age, 1 if str(sex_str).lower().startswith(\"m\") else 0]], np.float32)\n",
        "\n",
        "    p = model.predict({\"ecg\": x_ecg, \"demo\": x_demo}, verbose=0)[0]\n",
        "    label = CLASSES[int(np.argmax(p))]\n",
        "    return label, {CLASSES[i]: float(p[i]) for i in range(3)}\n",
        "\n",
        "print(\"\\nUsage example (after training):\")\n",
        "print('pred, probs = predict_single_rec(\"records500/00000/00001\", age=56, sex_str=\"male\")')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnMdiRmFvyQZ",
        "outputId": "8a90e76a-9c58-4312-e052-bae39c747ae4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Classification Report (only classes present in y_test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Silent_MI     0.9827    0.4440    0.6117       768\n",
            "    Acute_MI     0.0992    0.8868    0.1784        53\n",
            "\n",
            "    accuracy                         0.4726       821\n",
            "   macro avg     0.5409    0.6654    0.3950       821\n",
            "weighted avg     0.9257    0.4726    0.5837       821\n",
            "\n",
            "Confusion Matrix (only present classes, in this order): ['Silent_MI', 'Acute_MI']\n",
            "[[341 427]\n",
            " [  6  47]]\n",
            "\n",
            "Overall accuracy: 0.4726\n",
            "Supports: {'Silent_MI': 768, 'Acute_MI': 53}\n",
            "\n",
            "Model saved to: /content/silent_mi_cnn_wfdb.h5\n",
            "\n",
            "Usage example (after training):\n",
            "pred, probs = predict_single_rec(\"records500/00000/00001\", age=56, sex_str=\"male\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== ECG JPEG -> MAT + WFDB converter (+ optional model inference) ==========\n",
        "# Robust version with deskew, optional px/mm override, safer resampling, and preview.\n",
        "# Outputs:\n",
        "#   /content/converted/<stem>_10s_100Hz.mat   -> MATLAB file with key 'val' (µV, int16) shape (12, T)\n",
        "#   /content/converted/<stem>_10s_100Hz.hea/.dat  -> WFDB (fs=100 Hz, units=uV)\n",
        "\n",
        "import os, math, io, time, numpy as np\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import cv2\n",
        "from skimage.morphology import skeletonize\n",
        "from scipy.signal import find_peaks\n",
        "from scipy.io import savemat\n",
        "import matplotlib.pyplot as plt\n",
        "import wfdb\n",
        "import tensorflow as tf\n",
        "\n",
        "# ------------------ Config ------------------\n",
        "OUT_DIR = Path(\"/content/converted\")\n",
        "OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Paper assumptions (can tweak)\n",
        "ASSUME_MM_PER_MV  = 10.0   # 10 mm = 1 mV\n",
        "ASSUME_MM_PER_SEC = 25.0   # 25 mm/sec\n",
        "TARGET_FS         = 100    # Hz\n",
        "TARGET_SECONDS    = 10.0\n",
        "TARGET_LEN        = int(TARGET_FS * TARGET_SECONDS)\n",
        "\n",
        "# Layout (4x3 typical 12-lead page)\n",
        "GRID_ROWS, GRID_COLS = 4, 3\n",
        "LEAD_NAMES = [\"I\",\"II\",\"III\",\"aVR\",\"aVL\",\"aVF\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"]\n",
        "\n",
        "# Optional manual overrides (set to None to auto-detect)\n",
        "FORCE_PX_PER_MM = None     # e.g., 10.0 if you know your scan scale\n",
        "REVERSE_POLARITY = False   # True if your deflections look inverted after preview\n",
        "\n",
        "# ------------------ Helpers ------------------\n",
        "def read_image_rgb(path):\n",
        "    img = cv2.imread(str(path))\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Cannot read image: {path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def deskew_image(img_rgb):\n",
        "    \"\"\"Estimate a small skew angle from grid lines and deskew image.\"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(cv2.GaussianBlur(gray, (3,3), 0), 50, 120)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=180)\n",
        "    if lines is None:\n",
        "        return img_rgb\n",
        "    # Get angles near 0º or 90º (grid)\n",
        "    angles = []\n",
        "    for rho, theta in lines[:,0,:]:\n",
        "        deg = theta * 180.0 / np.pi\n",
        "        # Normalize angle to [-90, 90]\n",
        "        if deg > 90: deg -= 180\n",
        "        # Keep near 0 or ±90\n",
        "        if abs(deg) < 15 or abs(abs(deg)-90) < 15:\n",
        "            angles.append(deg)\n",
        "    if not angles:\n",
        "        return img_rgb\n",
        "    angle = float(np.median(angles))\n",
        "    if abs(angle) < 0.5:\n",
        "        return img_rgb\n",
        "    # Rotate\n",
        "    h, w = img_rgb.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
        "    rotated = cv2.warpAffine(img_rgb, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
        "    return rotated\n",
        "\n",
        "def estimate_pixels_per_mm(img_rgb):\n",
        "    \"\"\"Estimate grid spacing via projection peaks; fallback to 10 px/mm.\"\"\"\n",
        "    if FORCE_PX_PER_MM:\n",
        "        return float(FORCE_PX_PER_MM)\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    edges = cv2.Canny(blur, 30, 80)\n",
        "    vproj = edges.sum(axis=0)\n",
        "    hproj = edges.sum(axis=1)\n",
        "\n",
        "    def _period(sig):\n",
        "        pk, _ = find_peaks(sig, distance=8, prominence=np.percentile(sig, 80))\n",
        "        if len(pk) < 5:\n",
        "            return None\n",
        "        diffs = np.diff(pk)\n",
        "        return float(np.median(diffs)) if len(diffs) else None\n",
        "\n",
        "    pv = _period(vproj)\n",
        "    ph = _period(hproj)\n",
        "    cands = [p for p in [pv, ph] if p and 3 <= p <= 30]\n",
        "    if not cands:\n",
        "        return 10.0\n",
        "    period = float(np.median(cands))\n",
        "    px_per_mm = period/5.0 if period >= 14 else period  # if likely 5mm heavy lines\n",
        "    return float(np.clip(px_per_mm, 4.0, 16.0))\n",
        "\n",
        "def split_into_leads(img_rgb):\n",
        "    \"\"\"Split 4x3 equal tiles with margin crop.\"\"\"\n",
        "    H, W = img_rgb.shape[:2]\n",
        "    tiles = []\n",
        "    row_h = H // GRID_ROWS\n",
        "    col_w = W // GRID_COLS\n",
        "    for r in range(GRID_ROWS):\n",
        "        for c in range(GRID_COLS):\n",
        "            y0 = r*row_h; y1 = (r+1)*row_h if r<GRID_ROWS-1 else H\n",
        "            x0 = c*col_w; x1 = (c+1)*col_w if c<GRID_COLS-1 else W\n",
        "            my = int(0.08*(y1-y0)); mx = int(0.06*(x1-x0))\n",
        "            y0i, y1i = y0+my, y1-my\n",
        "            x0i, x1i = x0+mx, x1-mx\n",
        "            tile = img_rgb[max(0,y0i):min(H,y1i), max(0,x0i):min(W,x1i)]\n",
        "            tiles.append(tile)\n",
        "    return tiles\n",
        "\n",
        "def trace_signal_from_tile(tile_rgb):\n",
        "    \"\"\"Return (T,) trace in pixel rows (top=0).\"\"\"\n",
        "    gray = cv2.cvtColor(tile_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    norm = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    # Adaptive kernel based on tile size\n",
        "    th = max(5, int(min(tile_rgb.shape[:2]) * 0.03) | 1)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (th, th))\n",
        "    bg = cv2.morphologyEx(norm, cv2.MORPH_OPEN, kernel)\n",
        "    fg = cv2.subtract(norm, bg)\n",
        "    # Threshold + skeleton\n",
        "    _, bw = cv2.threshold(fg, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    bw = 255 - bw\n",
        "    bw = (bw > 0).astype(np.uint8)\n",
        "    skel = skeletonize(bw > 0)\n",
        "\n",
        "    H, W = skel.shape\n",
        "    y_trace = np.full(W, np.nan, dtype=np.float32)\n",
        "    for x in range(W):\n",
        "        ys = np.where(skel[:, x])[0]\n",
        "        if ys.size:\n",
        "            y_trace[x] = np.median(ys)\n",
        "        else:\n",
        "            col = gray[:, x]\n",
        "            y_trace[x] = float(np.argmin(col))\n",
        "    # Interp missing\n",
        "    isnan = np.isnan(y_trace)\n",
        "    if np.any(isnan):\n",
        "        idx = np.where(~isnan)[0]\n",
        "        if idx.size == 0:\n",
        "            raise ValueError(\"No trace found in tile.\")\n",
        "        y_trace = np.interp(np.arange(W), idx, y_trace[idx]).astype(np.float32)\n",
        "    return y_trace\n",
        "\n",
        "def pixels_to_mv(y_pix, px_per_mm):\n",
        "    \"\"\"Map pixel rows to mV relative to median baseline. Upward positive.\"\"\"\n",
        "    baseline = float(np.median(y_pix))\n",
        "    delta_pix = baseline - y_pix\n",
        "    delta_mm  = delta_pix / float(px_per_mm)\n",
        "    mv = delta_mm / ASSUME_MM_PER_MV\n",
        "    if REVERSE_POLARITY:\n",
        "        mv = -mv\n",
        "    return mv.astype(np.float32)\n",
        "\n",
        "def build_time_axis(n_cols, px_per_mm):\n",
        "    mm_per_col = 1.0 / float(px_per_mm)\n",
        "    sec_per_col = mm_per_col / ASSUME_MM_PER_SEC\n",
        "    return np.arange(n_cols, dtype=np.float32) * sec_per_col\n",
        "\n",
        "def resample_to_target(x_mv, t_sec, fs_target=TARGET_FS, T=TARGET_SECONDS):\n",
        "    t_uniform = np.linspace(0.0, T, int(fs_target*T), endpoint=False)\n",
        "    # clip t to [0, t_max] and hold edges\n",
        "    t_max = max(t_sec[-1], 1e-6)\n",
        "    t_clip = np.clip(t_uniform, 0.0, t_max)\n",
        "    # simple linear interp on clipped domain, with edge values held\n",
        "    x_interp = np.interp(t_clip, t_sec, x_mv, left=x_mv[0], right=x_mv[-1])\n",
        "    return x_interp.astype(np.float32)\n",
        "\n",
        "def convert_image_to_signals(img_path, out_stem=\"custom_record\"):\n",
        "    # 0) Load + deskew\n",
        "    img0 = read_image_rgb(img_path)\n",
        "    img  = deskew_image(img0)\n",
        "\n",
        "    # 1) scale + split\n",
        "    px_per_mm = estimate_pixels_per_mm(img)\n",
        "    tiles = split_into_leads(img)\n",
        "    if len(tiles) != 12:\n",
        "        raise ValueError(f\"Expected 12 tiles, got {len(tiles)}\")\n",
        "\n",
        "    # 2) trace each lead\n",
        "    signals_mv = []\n",
        "    for tile in tiles:\n",
        "        y_pix = trace_signal_from_tile(tile)\n",
        "        mv    = pixels_to_mv(y_pix, px_per_mm)\n",
        "        tsec  = build_time_axis(len(mv), px_per_mm)\n",
        "        mv_rs = resample_to_target(mv, tsec, fs_target=TARGET_FS, T=TARGET_SECONDS)\n",
        "        signals_mv.append(mv_rs)\n",
        "\n",
        "    # 3) stack + save\n",
        "    sig_mv = np.stack(signals_mv, axis=0)         # (12, T) in mV\n",
        "    sig_uV = (sig_mv * 1000.0).astype(np.float32) # µV (float)\n",
        "    sig_uV_i16 = np.clip(sig_uV, -32768, 32767).astype(np.int16)\n",
        "\n",
        "    # MAT: PTB-XL style (key 'val' in µV int16, shape (12, T))\n",
        "    mat_path = OUT_DIR / f\"{out_stem}.mat\"\n",
        "    savemat(str(mat_path), {\"val\": sig_uV_i16})\n",
        "    print(f\"✔ Saved MAT: {mat_path}\")\n",
        "\n",
        "    # WFDB: sanitize + write with wide format\n",
        "    sig_uV_sanitized = np.nan_to_num(sig_uV, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    sig_uV_sanitized = np.clip(sig_uV_sanitized, -1_000_000.0, 1_000_000.0)\n",
        "\n",
        "    wfdb.wrsamp(\n",
        "        record_name=str(out_stem),\n",
        "        fs=TARGET_FS,\n",
        "        units=[\"uV\"] * 12,\n",
        "        sig_name=LEAD_NAMES,\n",
        "        p_signal=sig_uV_sanitized.T.astype(np.float64),  # (T, 12)\n",
        "        fmt=[\"32\"] * 12,\n",
        "        adc_gain=[1.0] * 12,\n",
        "        baseline=[0] * 12,\n",
        "        write_dir=str(OUT_DIR),\n",
        "    )\n",
        "    hea_path = OUT_DIR / f\"{out_stem}.hea\"\n",
        "    dat_path = OUT_DIR / f\"{out_stem}.dat\"\n",
        "    print(f\"✔ Saved WFDB: {hea_path}, {dat_path}\")\n",
        "\n",
        "    # Quick preview (first 3 leads)\n",
        "    plt.figure(figsize=(10,4))\n",
        "    for i, lead in enumerate([0,1,6]):  # I, II, V1\n",
        "        plt.plot(sig_mv[i] + i*2.0, label=LEAD_NAMES[[0,1,6][i]])\n",
        "    plt.title(\"Preview (arbitrary stacked offset, mV)\")\n",
        "    plt.xlabel(\"samples @100 Hz\"); plt.legend(); plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return sig_mv, str(mat_path), str(hea_path)\n",
        "\n",
        "def predict_with_trained_model(sig_mv, age_years=56, sex_str=\"male\", model_path=\"/content/silent_mi_cnn_wfdb.h5\"):\n",
        "    \"\"\"Run trained ECG+demo model (12 x 1000 mV) if present.\"\"\"\n",
        "    if not Path(model_path).exists():\n",
        "        print(\"⚠ Model not found; skipping inference.\")\n",
        "        return None, None\n",
        "\n",
        "    # match training preprocessing: per-lead z-normalization\n",
        "    sig = sig_mv.copy()\n",
        "    mu = np.median(sig, axis=1, keepdims=True)\n",
        "    sd = np.std(sig, axis=1, keepdims=True) + 1e-6\n",
        "    sig = (sig - mu) / sd\n",
        "\n",
        "    x_ecg  = sig[np.newaxis, ..., None].astype(np.float32)\n",
        "    def sex_to_num(s):\n",
        "        s = str(s).strip().lower()\n",
        "        if s.startswith(\"m\"): return 1\n",
        "        if s.startswith(\"f\"): return 0\n",
        "        try: return 1 if float(s)>0.5 else 0\n",
        "        except: return 0\n",
        "    x_demo = np.array([[float(age_years), sex_to_num(sex_str)]], np.float32)\n",
        "\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    probs = model.predict({\"ecg\": x_ecg, \"demo\": x_demo}, verbose=0)[0]\n",
        "    classes = [\"Normal\",\"Silent_MI\",\"Acute_MI\"]\n",
        "    pred = classes[int(np.argmax(probs))]\n",
        "    return pred, {classes[i]: float(probs[i]) for i in range(3)}\n",
        "\n",
        "# ------------------ Upload & run ------------------\n",
        "print(\"📤 Upload your ECG image (jpg/png):\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise SystemExit(\"No file uploaded.\")\n",
        "\n",
        "img_name = list(uploaded.keys())[0]\n",
        "img_path = Path(\"/content\") / img_name\n",
        "stem = img_path.stem\n",
        "\n",
        "# Convert\n",
        "out_stem = f\"{stem}_10s_100Hz\"\n",
        "sig_mv, mat_path, hea_path = convert_image_to_signals(img_path, out_stem=out_stem)\n",
        "\n",
        "# Optional: predict with your trained model (if present)\n",
        "AGE = 56\n",
        "SEX = \"male\"\n",
        "pred, probs = predict_with_trained_model(sig_mv, AGE, SEX, model_path=\"/content/silent_mi_cnn_wfdb.h5\")\n",
        "if pred is not None:\n",
        "    print(\"\\n🔮 Model prediction:\")\n",
        "    print(\"  Label:\", pred)\n",
        "    print(\"  Probabilities:\")\n",
        "    for k, v in probs.items():\n",
        "        print(f\"    {k:10s}: {v*100:6.2f}%\")\n",
        "\n",
        "print(\"\\n✅ Done.\")\n",
        "print(\"Submission files:\")\n",
        "print(\"  MAT :\", mat_path)\n",
        "print(\"  HEA :\", hea_path)\n",
        "print(\"  DAT :\", str(Path(hea_path).with_suffix(\".dat\")))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "b63DJL0CiMh1",
        "outputId": "f914105d-61ad-419f-f1c0-2d1c8be5e8e9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📤 Upload your ECG image (jpg/png):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-37a12ac9-2425-4dd5-bbc0-77230e7d3335\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-37a12ac9-2425-4dd5-bbc0-77230e7d3335\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving download.jpeg to download (2).jpeg\n",
            "✔ Saved MAT: /content/converted/download (2)_10s_100Hz.mat\n",
            "✔ Saved WFDB: /content/converted/download (2)_10s_100Hz.hea, /content/converted/download (2)_10s_100Hz.dat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAGGCAYAAACNL1mYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASiVJREFUeJzt3Xt8zvX/x/HntdO182YOm8OcRTSlkTaHSQ4tfJOKROZQ+ZaSdJCUQqVzOqjUV5SUqAjlsBSRQ47llAiR8yHbmB2v9++P/XZx2Yaxz66Nx/12263ren/en8/n9bn2nvbc+3OwGWOMAAAAAACAJTzcXQAAAAAAAJcygjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwBcpqpXr67evXu7uwxJ0q+//iofHx/9/fffRbrd6tWrq2PHjufst3DhQtlsNi1cuLBI9385a9Wqla666ipL9zFx4kTZbDbt3LmzyLa5cuVKxcbGKiAgQDabTevWrZMkzZ07V9dcc418fX1ls9l07NixIttnaZSZmanIyEi999577i4FAEoFgjcAFIPcgJD75evrqyuuuEIPPvigDhw44O7y3G7YsGHq3r27qlWr5u5SnD7//HONGTPG3WUUuaVLl+q555677INjfjIzM3XHHXfo6NGjevPNNzVp0iRVq1ZNR44cUdeuXeXn56exY8dq0qRJCggIKNJ9u3u8DRw4UDabTdu2bSuwz7Bhw2Sz2fT777/L29tbgwcP1gsvvKC0tLRirBQASieCNwAUo5EjR2rSpEl69913FRsbq/fff18xMTFKTU0t9lq2bNmijz76qNj3e6Z169bphx9+0H//+1+31dCyZUudPHlSLVu2dLa5OwhZZenSpRoxYgTBOx9//fWX/v77bz322GO677771LNnT5UpU0YrV65USkqKRo0apX79+qlnz57y9vYu0n27e7z16NHDWUdBvvjiC0VFRalhw4aSpD59+ujw4cNnXQcAkIPgDQDFKD4+Xj179tQ999yjiRMnatCgQdqxY4e+/fbbAtc5ceKEJbXY7fYiDw8XYsKECapataquv/76IttmYf+Q4eHhIV9fX3l4XNj/FtPS0uRwOC5o3aLcBi7OwYMHJUmhoaHn1X4padq0qWrXrq0vvvgi3+XLli3Tjh07nAFdyvk82rVrp4kTJxZTlQBQehG8AcCNWrduLUnasWOHJKl3794KDAzUX3/9pZtvvllBQUHOX3QdDofGjBmjBg0ayNfXV+Hh4erfv7/+/fdf5/Y6duyomjVr5ruvmJgYNW7c2Pk+v2u8jx07pkGDBikyMlJ2u121a9fWyy+/7BIIr732WnXp0sVlvaioKOcpqLm+/PJL2Ww2bd68+ayfwYwZM9S6dWvZbDaX9m+//VYdOnRQpUqVZLfbVatWLY0aNUrZ2dku/XKvJV69erVatmwpf39/PfXUUy595s+f77w+t379+vrmm29clp95jXerVq303Xff6e+//3ZeHlC9enWXvlOmTNHTTz+typUry9/fX8nJyTp69Kgee+wxRUVFKTAwUMHBwYqPj9dvv/2W7/7O3Ma6detks9n05ptv5vmcli5dKpvNVmAwyvXOO++oQYMG8vf3V5kyZdS4cWPnjORzzz2nxx9/XJJUo0YN57HlXiM9YcIEtW7dWhUqVJDdblf9+vX1/vvv57ufOXPmKC4uTkFBQQoODlaTJk3OOfM5f/58+fv7q3v37srKypIk/fHHH7r99tsVFhYmX19fNW7cWDNnzsyz7saNG9W6dWv5+fmpSpUqev755wv1h4off/xRLVq0UEBAgEJDQ3XLLbe4jM3evXsrLi5OknTHHXfIZrOpVatWatWqlRISEiRJTZo0kc1mc/7cbN26VbfddpsiIiLk6+urKlWq6M4771RSUpLLvj/77DNFR0fLz89PYWFhuvPOO7V7927n8rONt8LI/fdj165d6tixowIDA1W5cmWNHTtWkrR+/Xq1bt1aAQEBqlatWp7vV48ePfTHH39ozZo1ebb9+eefy2azqXv37i7tbdu21ZIlS3T06NFC1wsAlxMvdxcAAJezv/76S5JUtmxZZ1tWVpbat2+v5s2b67XXXpO/v78kqX///po4caL69OmjgQMHaseOHXr33Xe1du1a/fLLL/L29la3bt3Uq1cvrVy5Uk2aNHFu8++//9by5cv16quvFlhLamqq4uLitGfPHvXv319Vq1bV0qVLNXToUO3bt895GmyLFi1cwt/Ro0e1ceNGeXh4aPHixc7TUBcvXqzy5cvryiuvLHCfe/bs0a5du3TttdfmWTZx4kQFBgZq8ODBCgwM1I8//qjhw4crOTk5z3EcOXJE8fHxuvPOO9WzZ0+Fh4c7l23dulXdunXTf//7XyUkJGjChAm64447NHfuXLVt2zbfuoYNG6akpCT9888/zhAcGBjo0mfUqFHy8fHRY489pvT0dPn4+GjTpk2aMWOG7rjjDtWoUUMHDhzQuHHjFBcXp02bNqlSpUpn3Ua9evXUrFkzTZ48WY888ohL38mTJysoKEi33HJLgZ/nRx99pIEDB+r222/Xww8/rLS0NP3+++9asWKF7rrrLnXp0kV//vmnvvjiC7355psqV66cJKl8+fKSpPfff18NGjTQf/7zH3l5eWnWrFl64IEH5HA4NGDAAJfvTd++fdWgQQMNHTpUoaGhWrt2rebOnau77ror39pmz56t22+/Xd26ddPHH38sT09Pbdy4Uc2aNVPlypX15JNPKiAgQFOnTlXnzp319ddf69Zbb5Uk7d+/XzfccIOysrKc/T788EP5+fkV+Fmc7ocfflB8fLxq1qyp5557TidPntQ777yjZs2aac2aNapevbr69++vypUr68UXX9TAgQPVpEkT5ziqW7euPvzwQ40cOVI1atRQrVq1lJGRofbt2ys9PV0PPfSQIiIitGfPHs2ePVvHjh1TSEiIJOmFF17QM888o65du+qee+7RoUOH9M4776hly5Zau3atQkNDz2u8na/s7GzFx8erZcuWeuWVVzR58mQ9+OCDCggI0LBhw9SjRw916dJFH3zwgXr16qWYmBjVqFFDUk7wHjFihD7//HOXn8ns7GxNnTpVLVq0UNWqVV32Fx0dLWOMli5del43MgSAy5YBAFhuwoQJRpL54YcfzKFDh8zu3bvNlClTTNmyZY2fn5/5559/jDHGJCQkGEnmySefdFl/8eLFRpKZPHmyS/vcuXNd2pOSkozdbjePPvqoS79XXnnF2Gw28/fffzvbqlWrZhISEpzvR40aZQICAsyff/7psu6TTz5pPD09za5du4wxxkybNs1IMps2bTLGGDNz5kxjt9vNf/7zH9OtWzfneg0bNjS33nrrWT+XH374wUgys2bNyrMsNTU1T1v//v2Nv7+/SUtLc7bFxcUZSeaDDz7I079atWpGkvn666+dbUlJSaZixYqmUaNGzraffvrJSDI//fSTs61Dhw6mWrVqebaZ27dmzZp5akxLSzPZ2dkubTt27DB2u92MHDnyvLYxbtw4I8ls3rzZ2ZaRkWHKlSvn8v3Kzy233GIaNGhw1j6vvvqqkWR27NiRZ1l+n3n79u1NzZo1ne+PHTtmgoKCTNOmTc3Jkydd+jocDufruLg4Zy1ff/218fb2Nvfee6/L53PjjTeaqKgol++nw+EwsbGxpk6dOs62QYMGGUlmxYoVzraDBw+akJCQAo/ldNdcc42pUKGCOXLkiLPtt99+Mx4eHqZXr17Ottzvy7Rp01zWz/35XblypbNt7dq1+fY93c6dO42np6d54YUXXNrXr19vvLy8XNoLGm+Fkfvvx4svvuhs+/fff42fn5+x2WxmypQpzvY//vjDSDLPPvusyzaaNGliqlSp4vJ9yv13Zty4cXn2uXfvXiPJvPzyyxdVOwBc6jjVHACKUZs2bVS+fHlFRkbqzjvvVGBgoKZPn67KlSu79Lv//vtd3k+bNk0hISFq27atDh8+7PyKjo5WYGCgfvrpJ0lynto8depUGWOc63/55Ze6/vrr88xWnbmPFi1aqEyZMi77aNOmjbKzs/Xzzz9LypnxluR8v3jxYjVp0kRt27bV4sWLJeWcsr5hwwZn34IcOXJEklSmTJk8y06fzUxJSdHhw4fVokULpaam6o8//nDpa7fb1adPn3z3UalSJefMqZTzGfXq1Utr167V/v37z1rf2SQkJOSZcbXb7c7rxLOzs3XkyBEFBgaqbt26+Z6+m982unbtKl9fX02ePNnZNm/ePB0+fFg9e/Y8a02hoaH6559/tHLlygs6ptNrSUpK0uHDhxUXF6ft27c7T59OTExUSkqKnnzySfn6+rqsf+blAlLODbm6deum/v37a9y4cc7P5+jRo/rxxx/VtWtX5/f38OHDOnLkiNq3b6+tW7dqz549kqTvv/9e119/va677jrndsuXL+9yvXFB9u3bp3Xr1ql3794KCwtztjds2FBt27bV999/X4hP6JTcGe158+YVeE+Bb775Rg6HQ127dnX5mYqIiFCdOnWcP7dF7Z577nG+Dg0NVd26dRUQEKCuXbs62+vWravQ0FBt377dZd2ePXvqn3/+cf58Szmnmfv4+OiOO+7Is6/cn93Dhw8X9WEAwCWF4A0AxWjs2LFKTEzUTz/9pE2bNmn79u1q3769Sx8vLy9VqVLFpW3r1q1KSkpShQoVVL58eZev48ePO2/+JEndunXT7t27tWzZMkk5p7OvXr1a3bp1O2ttW7du1dy5c/Nsv02bNpJO3WAqPDxcderUcYbsxYsXq0WLFmrZsqX27t2r7du365dffpHD4Thn8M51+h8Jcm3cuFG33nqrQkJCFBwcrPLlyzuD55nX0FauXFk+Pj75brt27dp5AuEVV1whSRf1/Ofc03NP53A49Oabb6pOnTqy2+0qV66cypcvr99//z1PzQVtIzQ0VJ06dXK5/nby5MmqXLmy854ABRkyZIgCAwN13XXXqU6dOhowYIB++eWX8z6mX375RW3atHFeB12+fHnn9fK59edeHnE+z+jesWOHevbsqdtuu03vvPOOy/dh27ZtMsbomWeeyTPmnn32WUmnxtzff/+tOnXq5Nl+3bp1z1lD7rPh8+t75ZVX6vDhwxd0A8MaNWpo8ODB+t///qdy5cqpffv2Gjt2rMv3eevWrTLGqE6dOnmOcfPmzS4/t0XF19fXeelArpCQEFWpUiXPz0FISIjLPSIk6c4775Snp6dz/KWlpWn69OmKj4/P9w9kuT+7+f3RBQBwCtd4A0Axuu6661xucJaf02dNczkcDlWoUMFlFvR0p/+i3alTJ/n7+2vq1KmKjY3V1KlT5eHhke9s1Zn7aNu2rZ544ol8l+eGVUlq3ry5FixYoJMnT2r16tUaPny4rrrqKoWGhmrx4sXavHmzAgMD1ahRo7PuM/fa9jN/+T927Jji4uIUHByskSNHqlatWvL19dWaNWs0ZMiQPDfVOt9rfYtSfvt88cUX9cwzz6hv374aNWqUwsLC5OHhoUGDBuV7I7CC6u7Vq5emTZumpUuXKioqSjNnztQDDzxwzruuX3nlldqyZYtmz56tuXPn6uuvv9Z7772n4cOHa8SIEWdd96+//tKNN96oevXq6Y033lBkZKR8fHz0/fff680337ygO65XrFhRFStW1Pfff69Vq1a5jP3c7T322GN5/viUq3bt2oXeZ3F6/fXX1bt3b3377beaP3++Bg4cqNGjR2v58uWqUqWKHA6HbDab5syZI09PzzzrX+h13GeT337O1n7mH70qVKigtm3b6uuvv9bYsWM1a9YspaSkFHh2Qe7Pbu79AgAA+SN4A0ApUKtWLf3www9q1qzZOUNmQECAOnbsqGnTpumNN97Ql19+qRYtWuS5sVd++zh+/LhzhvtsWrRooQkTJmjKlCnKzs5WbGysPDw81Lx5c2fwjo2NLfCX/Vz16tWTdOqu7rkWLlyoI0eO6JtvvnF5tvaZ/c5H7szq6TNyf/75pySd9c7RFzKD99VXX+mGG27Q+PHjXdqPHTtWqGBy0003qXz58po8ebKaNm2q1NRU3X333ee1bkBAgLp166Zu3bopIyNDXbp00QsvvKChQ4fK19e3wOOaNWuW0tPTNXPmTJdLEs48HbpWrVqSpA0bNpwzGPv6+mr27Nlq3bq1brrpJi1atEgNGjSQJOfd9729vc855qpVq6atW7fmad+yZctZ18tdt6C+f/zxh8qVK6eAgIBzbqcgUVFRioqK0tNPP62lS5eqWbNm+uCDD/T888+rVq1aMsaoRo0aLn+4yk9JmjHu0aOH5s6dqzlz5ujzzz9XcHCwOnXqlG/f3J/Js91EEQDAqeYAUCp07dpV2dnZGjVqVJ5lWVlZOnbsmEtbt27dtHfvXv3vf//Tb7/9ds7TzHP3sWzZMs2bNy/PsmPHjjkf/ySdus775ZdfVsOGDZ3Xu7Zo0UILFizQqlWrzus088qVKysyMlKrVq1yac8N7KfPxmVkZOi999475zbPtHfvXk2fPt35Pjk5WZ9++qmuueYaRUREFLheQEBAvqeHn42np2eeGcRp06Y5r1U+X15eXurevbumTp2qiRMnKioqynm3+LPJvWY+l4+Pj+rXry9jjDIzMyXJGTLPHDP5feZJSUmaMGGCS7927dopKChIo0ePVlpamsuy/C4ZCAkJ0bx585wzqbmnqleoUEGtWrXSuHHjtG/fvjzrHTp0yPn65ptv1vLly/Xrr7+6LC/oDJDTVaxYUddcc40++eQTl2PesGGD5s+fr5tvvvmc28hPcnKyy8+ElBPCPTw8lJ6eLknq0qWLPD09NWLEiDyfjTHG5ft1IePNKp07d5a/v7/ee+89zZkzR126dMlzPX+u1atXy2azKSYmppirBIDShRlvACgF4uLi1L9/f40ePVrr1q1Tu3bt5O3tra1bt2ratGl66623dPvttzv75z4D/LHHHpOnp6duu+22c+7j8ccf18yZM9WxY0f17t1b0dHROnHihNavX6+vvvpKO3fudM7a1q5dWxEREdqyZYseeugh5zZatmypIUOGSNJ5X999yy23aPr06S6z0rGxsSpTpowSEhI0cOBA2Ww2TZo0Kd9gdy5XXHGF+vXrp5UrVyo8PFwff/yxDhw4kCdQnik6OlpffvmlBg8erCZNmigwMLDAWb9cHTt21MiRI9WnTx/FxsZq/fr1mjx5coHPVj+bXr166e2339ZPP/2kl19++bzWadeunSIiItSsWTOFh4dr8+bNevfdd9WhQwcFBQU5j0vKeWTanXfeKW9vb3Xq1Ent2rWTj4+POnXqpP79++v48eP66KOPVKFCBZdgHBwcrDfffFP33HOPmjRporvuuktlypTRb7/9ptTUVH3yySd56ipXrpwSExPVvHlztWnTRkuWLHE+X7p58+aKiorSvffeq5o1a+rAgQNatmyZ/vnnH+fzz5944glNmjRJN910kx5++GHn48SqVavm8uz4grz66quKj49XTEyM+vXr53ycWEhIiJ577rnz+mzP9OOPP+rBBx/UHXfcoSuuuEJZWVmaNGmSy89brVq19Pzzz2vo0KHauXOnOnfurKCgIO3YsUPTp0/Xfffdp8cee8z5fSlovLVq1UqLFi26oPF/IQIDA9W5c2fndd5nu4ldYmKimjVr5vJIRABAPor7NuoAcDnK73FE+UlISDABAQEFLv/www9NdHS08fPzM0FBQSYqKso88cQTZu/evXn69ujRw0gybdq0yXdbZz5OzBhjUlJSzNChQ03t2rWNj4+PKVeunImNjTWvvfaaycjIcOl7xx13GEnmyy+/dLZlZGQYf39/4+Pjk+dRUwVZs2aNkWQWL17s0v7LL7+Y66+/3vj5+ZlKlSqZJ554wsybNy/PY79Of2xVfsfYoUMHM2/ePNOwYUNjt9tNvXr18jwCKr/HiR0/ftzcddddJjQ01EhyPuqpoEdOGZPzOLFHH33UVKxY0fj5+ZlmzZqZZcuWmbi4OBMXF5dnf2d7FJUxxjRo0MB4eHg4Hzd3LuPGjTMtW7Y0ZcuWNXa73dSqVcs8/vjjJikpyaXfqFGjTOXKlY2Hh4fL47hmzpxpGjZsaHx9fU316tXNyy+/bD7++ON8H9k1c+ZMExsba/z8/ExwcLC57rrrzBdffOFcnt/3Zdu2baZixYrmyiuvNIcOHTLGGPPXX3+ZXr16mYiICOPt7W0qV65sOnbsaL766iuXdX///XcTFxdnfH19TeXKlc2oUaPM+PHjz+txYsbkPLquWbNmzno7derkfCRersI8Tmz79u2mb9++platWsbX19eEhYWZG264wfzwww959v3111+b5s2bm4CAABMQEGDq1atnBgwYYLZs2eLsU9B4M8aY6OhoExERcc5jLOjfj4J+RnJ/PvLz3XffGUmmYsWKeR6Rl+vYsWPGx8fH/O9//ztnbQBwubMZU0x/PgUAoAA33nijKlWqpEmTJrm7lBKlUaNGCgsL04IFC9xdCtwkJSVFYWFhGjNmjAYMGODuclyMGTNGr7zyiv766y+33OAQAEoTrvEGALjdiy++qC+//NL56CdIq1at0rp169SrVy93lwI3+vnnn1W5cmXde++97i7FRWZmpt544w09/fTThG4AOA/MeAMAUIJs2LBBq1ev1uuvv67Dhw9r+/btBd7YCgAAlA7MeAMAUIJ89dVX6tOnjzIzM/XFF18QugEAuAQw4w0AAAAAgIWY8QYAAAAAwEIEbwAAAAAALORV3Dt0OBzau3evgoKCZLPZinv3AAAAAABcNGOMUlJSVKlSJXl4nH1Ou9iD9969exUZGVncuwUAAAAAoMjt3r1bVapUOWufYg/eQUFBknKKCw4OLu7dAwAAAABw0ZKTkxUZGenMuGdT7ME79/Ty4OBggjcAAAAAoFQ7n0uoubkaAAAAAAAWIngDAAAAAGAhgjcAAAAAABYq9mu8AQAAAAAlm8PhUEZGhrvLcCtvb295enoWybYI3gAAAAAAp4yMDO3YsUMOh8PdpbhdaGioIiIizusGamdD8AYAAAAASJKMMdq3b588PT0VGRkpD4/L8+pkY4xSU1N18OBBSVLFihUvansEbwAAAACAJCkrK0upqamqVKmS/P393V2OW/n5+UmSDh48qAoVKlzUaeeX558vAAAAAAB5ZGdnS5J8fHzcXEnJkPvHh8zMzIvaDsEbAAAAAODiYq9pvlQU1edA8AYAAAAAwEJc4+1Gb6x+Q/N3znd3GQAAAAAgSSrnXU73VL5HSpI8TxbNo7QKy9fTV1WDq7pl31YheLuJMUaTNk1SliPL3aUAAAAAgCTJ4eNQtiNbWY4sObLd8zgxT9uFBf7evXvr2LFjmjFjRtEWVAQI3m5yMuukM3RPaD9Bdk+7mysCAAAAcLkzmUbmqFGVwCqy+7ono3jYLr0rognebpKckSxJ8vLwUnR4NDcvAAAAAOB2aWlp2pG0Q37efvL19nV3OZcMgreb5AbvYJ9gQjcAAACAEskYo5OZ2W7Zt5+35yWTlQjebpKSkSIpJ3gDAAAAQEl0MjNb9YfPc8u+N41sL3+fSyOyXnonz5cSyek5M95BPkFurgQAAAAAYKVL488HpVBKZs6MN8EbAAAAQEnl5+2pTSPbu23flwqCdxFwGEeh77yXO+PNqeYAAAAASiqbzXbJnO7tThd1qvlLL70km82mQYMGFVE5pc+EDRMU/Vm01h1cV6j1cq/xZsYbAAAAAC5tFxy8V65cqXHjxqlhw4ZFWU+p88bqN5TlyNKTi5/MsywtK03/pPyT73qn39UcAAAAAHDpuqDgffz4cfXo0UMfffSRypQpU9Q1lRoO43C+3nN8j/P10bSjchiHhi0Zppu/uVn3/3C/xv02TsYYZ5/c4M2MNwAAAABcvIkTJ2rGjBnuLiNfF3Sy/oABA9ShQwe1adNGzz//fFHXVGqcHrYlad3Bdfo37V8N/GmgyvmV0+GThyVJS/Ys0ZI9S1TGt4zuuOIO2Wy2UzPedma8AQAAAOBSVujgPWXKFK1Zs0YrV648r/7p6elKT093vk9OTi7sLkusbf9uc3l/95y7na9zQ/fpRi0fpZl/zVSnmp20M2mnJGa8AQAAAOBSV6jgvXv3bj388MNKTEyUr6/vea0zevRojRgx4oKKKymOph1VqD3UeefylIwUvbP2HW08vPGs64X7hyvMN0zHM48rPTtdB1MP6rdDv+m3Q785+4TZwyytHQAAAADgXjZz+oXH5zBjxgzdeuut8vQ89Ty17Oxs2Ww2eXh4KD093WWZlP+Md2RkpJKSkhQcXLJPs566Zar2Ht+r8RvGq06ZOhpw9QDdUPUG3f393fr98O/OfleUuUJ//vuny7rvtn5XcZFxLm27k3dr/IbxSkpPkiRVCqykR6IfkZcHt+cHAAAA4H5paWnasWOHatSocd6TrZeys30eycnJCgkJOa9sW6jEd+ONN2r9+vUubX369FG9evU0ZMiQPKFbkux2u+x2e2F2UyJsObpFo5aPcr7f+u9WDVo4SH5efjqZddKl7/1X369HFj7i0la7TO0824wMjtRzsc9ZUi8AAAAAoGQqVPAOCgrSVVdd5dIWEBCgsmXL5mkv7bIcWWoS0UQr96/UDZE3qHZobX22+bM8oVuS4qrE5WmrGFCxOMoEAAAAAJRwnONcgAblGujj9h/rWNoxBfkEydPDUxnZGfpk0yeSpFtq3aI9x/eoZ/2e8vb01qstX9X2pO1asW+FGkc0dl4PDgAAAAC4vF108F64cGERlFFyhfqGOl/HVo51Bu/4GvFqVrmZc9lNNW6SJD1wzQPFWh8AAAAAoGRjxrsQosOj5e3hLSOjqPJR7i4HAAAAAFAKELwLwe5p18zOM5VtshXsU7LvyA4AAAAAKBm4ELmQqgRVUbXgau4uAwAAAABwmt69e6tz5855XpcEBG8AAAAAACxE8AYAAAAAwEJc4w0AAAAAyJ8xUmaqe/bt7S/ZbO7ZdxEjeAMAAAAA8peZKr1YyT37fmqv5BPgnn0XMU41BwAAAADAQsx4AwAAAADy5+2fM/Psrn1fIgjeAAAAAID82WyXzOne7sSp5gAAAAAAWIjgDQAAAACAhTjVHAAAAABQ6k2cODHf1yUBM94AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAIBSq1OnTrrpppvyXbZ48WLZbDb9/vvvGjhwoKKjo2W323XNNdcUa40EbwAAAABAqdWvXz8lJibqn3/+ybNswoQJaty4sRo2bChJ6tu3r7p161bcJRK8AQAAAAClV8eOHVW+fHlNnDjRpf348eOaNm2a+vXrJ0l6++23NWDAANWsWbPYa/Qq9j0CAAAAAEoFY4xOZp10y779vPxks9nO2c/Ly0u9evXSxIkTNWzYMOc606ZNU3Z2trp37251qedE8AYAAAAA5Otk1kk1/bypW/a94q4V8vf2P6++ffv21auvvqpFixapVatWknJOM7/tttsUEhJiYZXnh1PNAQAAAAClWr169RQbG6uPP/5YkrRt2zYtXrzYeZq5uzHjDQAAAADIl5+Xn1bctcJt+y6Mfv366aGHHtLYsWM1YcIE1apVS3FxcRZVVzgEbwAAAABAvmw223mf7u1uXbt21cMPP6zPP/9cn376qe6///7zuka8OBC8AQAAAAClXmBgoLp166ahQ4cqOTlZvXv3dlm+bds2HT9+XPv379fJkye1bt06SVL9+vXl4+NjaW0EbwAAAADAJaFfv34aP368br75ZlWqVMll2T333KNFixY53zdq1EiStGPHDlWvXt3SugjeAAAAAIBLQkxMjIwx+S5buHBh8RZzGu5qDgAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAFwXdGfxy43A4imQ7PE4MAAAAACBJ8vb2ls1m06FDh1S+fHnZbDZ3l+QWxhhlZGTo0KFD8vDwkI+Pz0Vtj+ANAAAAAJAkeXp6qkqVKvrnn3+0c+dOd5fjdv7+/qpatao8PC7uZHGCNwAAAADAKTAwUHXq1FFmZqa7S3ErT09PeXl5FcmsP8EbAAAAAODC09NTnp6e7i7jksHN1QAAAAAAsBDBGwAAAAAACxG8AQAAAACwEMEbAAAAAAALEbwBAAAAALAQwRsAAAAAAAsRvAEAAAAAsBDBGwAAAAAACxG8AQAAAACwUKGC9/vvv6+GDRsqODhYwcHBiomJ0Zw5c6yqDQAAAACAUq9QwbtKlSp66aWXtHr1aq1atUqtW7fWLbfcoo0bN1pVHwAAAAAApZrNGGMuZgNhYWF69dVX1a9fv/Pqn5ycrJCQECUlJSk4OPhidg0AAAAAgFsUJtt6XehOsrOzNW3aNJ04cUIxMTEXuhkAAAAAAC5phQ7e69evV0xMjNLS0hQYGKjp06erfv36BfZPT09Xenq6831ycvKFVQoAAAAAQClU6Lua161bV+vWrdOKFSt0//33KyEhQZs2bSqw/+jRoxUSEuL8ioyMvKiCAQAAAAAoTS76Gu82bdqoVq1aGjduXL7L85vxjoyM5BpvAAAAAECpVSzXeOdyOBwuwfpMdrtddrv9YncDAAAAAECpVKjgPXToUMXHx6tq1apKSUnR559/roULF2revHlW1QcAAAAAQKlWqOB98OBB9erVS/v27VNISIgaNmyoefPmqW3btlbVBwAAAABAqVao4D1+/Hir6gAAAAAA4JJU6LuaAwAAAACA80fwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIEbwAAAAAALETwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIEbwAAAAAALETwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIEbwAAAAAALETwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIEbwAAAAAALETwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIEbwAAAAAALETwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIEbwAAAAAALETwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIEbwAAAAAALETwBgAAAADAQgRvAAAAAAAsRPAGAAAAAMBCBG8AAAAAACxE8AYAAAAAwEIE7wuRnSk5HO6uAgAAAABQChC8Cyv9uPTW1dJnt7q7EgAAAABAKeDl7gJKnW0/SMl7cr4cDsmDv10AAAAAAApGajxfaydL/2srHdx8qu3kvwX3375IGt9OOrzV+toAAAAAACUWwft8ffuA9M+v0qKXTrWlHi64/+LXpN0rpLWTrK8NAAAAAFBiFSp4jx49Wk2aNFFQUJAqVKigzp07a8uWLVbVVnIUdCO1v5dKX/XNmQV3ZEvTekszB0qZadKuFTl98pvx/uN7aVof6fghy0oGAAAAAJQMhQreixYt0oABA7R8+XIlJiYqMzNT7dq104kTJ6yqr2RI2Zt/+3ePShu+lt67Xtr3m7RxurTmE+nPOVJ2ek6fw3+6rrPtB2lKd2njN9LvU6ytGwAAAADgdoW6udrcuXNd3k+cOFEVKlTQ6tWr1bJlyyItrEQp6Dptk33q9cLTTkFfOf7U66M7pKwMyctHMkZaMPLUsv0b8m7zxxek9VOlhFlSaNWLqxsAAAAA4HYXdVfzpKQkSVJYWFiBfdLT05Wenu58n5ycfDG7LF7HD0lfdDv7TdRybZ136vXOxadem2zp635S+XrSgY05M+O5/vlVSj0q+YdJJ45Ic56QNnyVs+y3KVLcE0VzHAAAAAAAt7ngm6s5HA4NGjRIzZo101VXXVVgv9GjRyskJMT5FRkZeaG7LH5b50t7VktHt7u2h9U8v/WDKuX8d/NM6edXpC3f5by/8j85/z26PeeZ4CcOS3MePxW6pZwbswEAAAAASr0LnvEeMGCANmzYoCVLlpy139ChQzV48GDn++Tk5NITvo8fyPlv2do5M9bX3Zfz/uBmae6Qs68bWlXq/H7OY8hsNkk2KShCqtJEqtNWGvn/ZwmkJ0uv15UcWTnvK10r7V0j7VouZWdKnt6WHBoAAAAAoHhcUPB+8MEHNXv2bP3888+qUqXKWfva7XbZ7fYLKs7tjh/M+W+9jlLbEafaT5zH3cgb95WqN8/5yk+9jtIfs3Ne54buJvdI8a9Kr9aSTh6V5j8jRURdeP0AAAAAUNr4h0l1491dRZEqVPA2xuihhx7S9OnTtXDhQtWoUcOqukqG3BnvwHDX9rDTjtsenDNrLUk1WkrlrsiZHW9yz9m3ffsE6eBG6X9tch5F1uUj6arbJA8P6YanpO8fk1a8X3THAgAAAAClQcVrLu/gPWDAAH3++ef69ttvFRQUpP3790uSQkJC5OfnZ0mBbpU74x1YwbW90rWnZqzr/0fas0Y6uEm6/oHzHyBePlKlRlKvmZKXr1Ql+tSyJvdI2RnS9oVFchgAAAAAUGqc7z21ShGbMcacd2ebLd/2CRMmqHfv3ue1jeTkZIWEhCgpKUnBwcHnu2v3eCdaOrJN6v1d3lPGs7Nybr4W2VTKSsu5UVqNFu6pEwAAAABQrAqTbQt9qvllxTnjHZ53maeXVO/mU+9DKhdPTQAAAACAUuWCHyd2yctIPXXt9pmnmgMAAAAAcJ4I3gU58f+z3V6+OTdQAwAAAADgAhC8C3L6jdUKuLYdAAAAAIBzuaDneF8WwmpKt413dxUAAAAAgFKO4F2QgHJS1O3urgIAAAAAUMpxqjkAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGAhgjcAAAAAABYieAMAAAAAYCGCNwAAAAAAFiJ4AwAAAABgIYI3AAAAAAAWIngDAAAAAGChQgfvn3/+WZ06dVKlSpVks9k0Y8YMC8oCAAAAAODSUOjgfeLECV199dUaO3asFfUAAAAAAHBJ8SrsCvHx8YqPj7eiFgAAAAAALjmFDt6FlZ6ervT0dOf75ORkq3cJAAAAAECJYfnN1UaPHq2QkBDnV2RkpNW7BAAAAACgxLA8eA8dOlRJSUnOr927d1u9SwAAAAAASgzLTzW32+2y2+1W7wYAAAAAgBKJ53gDAAAAAGChQs94Hz9+XNu2bXO+37Fjh9atW6ewsDBVrVq1SIsDAAAAAKC0K3TwXrVqlW644Qbn+8GDB0uSEhISNHHixCIrDAAAAACAS0Ghg3erVq1kjLGiFgAAAAAALjlc4w0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFjIy90FlFRJJzO1csfRApdfHRmq8kH2YqwIAAAAAFAaEbwLsOtIqu75dFWBy2tXCNQPg+POuo30rGztPpqqWuUDZbPZirpEAAAAAEApQPAugJ+Ph66ODM3Tnu1waMOeZG0/dFzGmLMG6qFfr9c3a/foqsrBmtY/Vn4+nhZWDAAAAAAoiQjeBahdIUjfDmiWpz0tM1v1npkrh5FOZGQr0F7wR7hpX7IkacOeZG3en6xrq5axrF4AAAAAQMnEzdUKye7lIW/PnFnu5JOZZ+37b2qG8/WJ9CxL6wIAAAAAlEwE70Ky2WwK9vWWJCWnFRy8jTE6eoLgDQAAAACXO4L3BQj2ywneKWkFh+mU9CxlZptT78/SFwAAAABw6SJ4X4Ag35zrus92qvnR4xku75nxBgAAAIDLE8H7ApzPqeZHTpwRvDOyLa0JAAAAAFAyEbwvQLBfzoz32U4fP3pG8H513hZN+GVHnn5/7E/WzsMnirZAAAAAAECJQfC+AEH2/5/xPsup5keOp+dpGzFrk1JOmyU/lpqhm8YsVqvXFsrhMHn6AwAAAABKvwsK3mPHjlX16tXl6+urpk2b6tdffy3qukq03Bnv5LPMeJ95qnmuZX8dcb7++0iq8/WhfII6AAAAAKD08yrsCl9++aUGDx6sDz74QE2bNtWYMWPUvn17bdmyRRUqVLCixhIn9xrvlLNc4517qnmAj6fL9d1Lth1WuwYRkqSDKafC9q6jqUo+maka5QLk5emhoycy9Mf+ZCvKBwAAAIASK9DupYZVQt1dRpEqdPB+4403dO+996pPnz6SpA8++EDfffedPv74Yz355JNFXmBJdOqu5ue+xrtq2QBt3ncqQC/964iysh36Zu0evfXDVmf7HR8skyQ1rBKiB2+orcFTf9Nx7oQOAAAA4DITVTlEsx5q7u4yilShgndGRoZWr16toUOHOts8PDzUpk0bLVu2LN910tPTlZ5+amY3Obn0z+LmPsf7u/X7tOWNRfL38VRsrXIKtHtKkhpUCtHh/z91vGqYn0vw3nbwuB6d9pu+Xbc3323//k+S7pu0WpIUHmx3zq4DAAAAwOWgapi/u0socoUK3ocPH1Z2drbCw8Nd2sPDw/XHH3/ku87o0aM1YsSIC6+wBDo9DG87eFxSTmDOT7WyAXnaCgrd19UI0687jkqSygb46KfHWsnfp9AnJQAAAAAAShDLU93QoUM1ePBg5/vk5GRFRkZavVtLXVutjK4ID9TVVULV5doq2nnkxP8Hb6MVO45q+6FTjweLLMRfa57pUF+j52zW0r+O6PnOVxG6AQAAAOASUKhkV65cOXl6eurAgQMu7QcOHFBERES+69jtdtnt9guvsAQKC/DR/EfinO9japVV9+tyXm/am6yb317sXHb6aRK3XFNJ367bKx9PDw2Jr6dRsze5bLdBpWB9cHe0dh9NVYNKIdYeBAAAAACgWBTqcWI+Pj6Kjo7WggULnG0Oh0MLFixQTExMkRdXGlUM8XV5X+204N23WQ19ce/1WvLkDeodW93Z/nj7upr1YHN5eNgU7OtN6AYAAACAS0ihz2UePHiwEhIS1LhxY1133XUaM2aMTpw44bzL+eUu1N/1Zmjlg07N9gf5eunqyFDn++8GNldSaqZia5crrvIAAAAAAMWs0MG7W7duOnTokIYPH679+/frmmuu0dy5c/PccO1yZbPZXN77+3gqpmZZnczMznOjNWa2AQAAAODSZzPGmOLcYXJyskJCQpSUlKTg4ODi3HWxqf7kd87XO1/qoNyP+MxQDgAAAAAonQqTbbltdjEgcAMAAADA5atQN1fD+al0xg3WAAAAAACXL4K3Bd7vGa06FQL1ce/G7i4FAAAAAOBmnGpugasjQ5U4OO7cHQEAAAAAlzxmvAEAAAAAsBDBGwAAAAAACxG8AQAAAACwEMEbAAAAAAALEbwBAAAAALAQwRsAAAAAAAsRvAEAAAAAsBDBGwAAAAAACxG8AQAAAACwEMEbAAAAAAALEbwBAAAAALCQV3Hv0BgjSUpOTi7uXQMAAAAAUCRyM21uxj2bYg/eKSkpkqTIyMji3jUAAAAAAEUqJSVFISEhZ+1jM+cTz4uQw+HQ3r17FRQUJJvNVpy7LrTk5GRFRkZq9+7dCg4Odnc5wDkxZlHaMGZR2jBmUdowZlEalZZxa4xRSkqKKlWqJA+Ps1/FXewz3h4eHqpSpUpx7/aiBAcHl+hvOHAmxixKG8YsShvGLEobxixKo9Iwbs81052Lm6sBAAAAAGAhgjcAAAAAABYieJ+F3W7Xs88+K7vd7u5SgPPCmEVpw5hFacOYRWnDmEVpdCmO22K/uRoAAAAAAJcTZrwBAAAAALAQwRsAAAAAAAsRvAEAAAAAsBDBuwBjx45V9erV5evrq6ZNm+rXX391d0m4TI0ePVpNmjRRUFCQKlSooM6dO2vLli0ufdLS0jRgwACVLVtWgYGBuu2223TgwAGXPrt27VKHDh3k7++vChUq6PHHH1dWVlZxHgouUy+99JJsNpsGDRrkbGPMoqTZs2ePevbsqbJly8rPz09RUVFatWqVc7kxRsOHD1fFihXl5+enNm3aaOvWrS7bOHr0qHr06KHg4GCFhoaqX79+On78eHEfCi4D2dnZeuaZZ1SjRg35+fmpVq1aGjVqlE6/dRNjFu72888/q1OnTqpUqZJsNptmzJjhsryoxujvv/+uFi1ayNfXV5GRkXrllVesPrQLQvDOx5dffqnBgwfr2Wef1Zo1a3T11Verffv2OnjwoLtLw2Vo0aJFGjBggJYvX67ExERlZmaqXbt2OnHihLPPI488olmzZmnatGlatGiR9u7dqy5dujiXZ2dnq0OHDsrIyNDSpUv1ySefaOLEiRo+fLg7DgmXkZUrV2rcuHFq2LChSztjFiXJv//+q2bNmsnb21tz5szRpk2b9Prrr6tMmTLOPq+88orefvttffDBB1qxYoUCAgLUvn17paWlOfv06NFDGzduVGJiombPnq2ff/5Z9913nzsOCZe4l19+We+//77effddbd68WS+//LJeeeUVvfPOO84+jFm424kTJ3T11Vdr7Nix+S4vijGanJysdu3aqVq1alq9erVeffVVPffcc/rwww8tP75CM8jjuuuuMwMGDHC+z87ONpUqVTKjR492Y1VAjoMHDxpJZtGiRcYYY44dO2a8vb3NtGnTnH02b95sJJlly5YZY4z5/vvvjYeHh9m/f7+zz/vvv2+Cg4NNenp68R4ALhspKSmmTp06JjEx0cTFxZmHH37YGMOYRckzZMgQ07x58wKXOxwOExERYV599VVn27Fjx4zdbjdffPGFMcaYTZs2GUlm5cqVzj5z5swxNpvN7Nmzx7ricVnq0KGD6du3r0tbly5dTI8ePYwxjFmUPJLM9OnTne+Laoy+9957pkyZMi6/GwwZMsTUrVvX4iMqPGa8z5CRkaHVq1erTZs2zjYPDw+1adNGy5Ytc2NlQI6kpCRJUlhYmCRp9erVyszMdBmz9erVU9WqVZ1jdtmyZYqKilJ4eLizT/v27ZWcnKyNGzcWY/W4nAwYMEAdOnRwGZsSYxYlz8yZM9W4cWPdcccdqlChgho1aqSPPvrIuXzHjh3av3+/y5gNCQlR06ZNXcZsaGioGjdu7OzTpk0beXh4aMWKFcV3MLgsxMbGasGCBfrzzz8lSb/99puWLFmi+Ph4SYxZlHxFNUaXLVumli1bysfHx9mnffv22rJli/79999iOprz4+XuAkqaw4cPKzs72+WXPUkKDw/XH3/84aaqgBwOh0ODBg1Ss2bNdNVVV0mS9u/fLx8fH4WGhrr0DQ8P1/79+5198hvTucuAojZlyhStWbNGK1euzLOMMYuSZvv27Xr//fc1ePBgPfXUU1q5cqUGDhwoHx8fJSQkOMdcfmPy9DFboUIFl+VeXl4KCwtjzKLIPfnkk0pOTla9evXk6emp7OxsvfDCC+rRo4ckMWZR4hXVGN2/f79q1KiRZxu5y06/ZMjdCN5AKTJgwABt2LBBS5YscXcpQIF2796thx9+WImJifL19XV3OcA5ORwONW7cWC+++KIkqVGjRtqwYYM++OADJSQkuLk6IK+pU6dq8uTJ+vzzz9WgQQOtW7dOgwYNUqVKlRizQAnFqeZnKFeunDw9PfPcXffAgQOKiIhwU1WA9OCDD2r27Nn66aefVKVKFWd7RESEMjIydOzYMZf+p4/ZiIiIfMd07jKgKK1evVoHDx7UtddeKy8vL3l5eWnRokV6++235eXlpfDwcMYsSpSKFSuqfv36Lm1XXnmldu3aJenUmDvb7wYRERF5bsKalZWlo0ePMmZR5B5//HE9+eSTuvPOOxUVFaW7775bjzzyiEaPHi2JMYuSr6jGaGn6fYHgfQYfHx9FR0drwYIFzjaHw6EFCxYoJibGjZXhcmWM0YMPPqjp06frxx9/zHM6TXR0tLy9vV3G7JYtW7Rr1y7nmI2JidH69etd/vFKTExUcHBwnl82gYt14403av369Vq3bp3zq3HjxurRo4fzNWMWJUmzZs3yPKbxzz//VLVq1SRJNWrUUEREhMuYTU5O1ooVK1zG7LFjx7R69Wpnnx9//FEOh0NNmzYthqPA5SQ1NVUeHq6/xnt6esrhcEhizKLkK6oxGhMTo59//lmZmZnOPomJiapbt26JOs1cEnc1z8+UKVOM3W43EydONJs2bTL33XefCQ0Ndbm7LlBc7r//fhMSEmIWLlxo9u3b5/xKTU119vnvf/9rqlatan788UezatUqExMTY2JiYpzLs7KyzFVXXWXatWtn1q1bZ+bOnWvKly9vhg4d6o5DwmXo9LuaG8OYRcny66+/Gi8vL/PCCy+YrVu3msmTJxt/f3/z2WefOfu89NJLJjQ01Hz77bfm999/N7fccoupUaOGOXnypLPPTTfdZBo1amRWrFhhlixZYurUqWO6d+/ujkPCJS4hIcFUrlzZzJ492+zYscN88803ply5cuaJJ55w9mHMwt1SUlLM2rVrzdq1a40k88Ybb5i1a9eav//+2xhTNGP02LFjJjw83Nx9991mw4YNZsqUKcbf39+MGzeu2I/3XAjeBXjnnXdM1apVjY+Pj7nuuuvM8uXL3V0SLlOS8v2aMGGCs8/JkyfNAw88YMqUKWP8/f3Nrbfeavbt2+eynZ07d5r4+Hjj5+dnypUrZx599FGTmZlZzEeDy9WZwZsxi5Jm1qxZ5qqrrjJ2u93Uq1fPfPjhhy7LHQ6HeeaZZ0x4eLix2+3mxhtvNFu2bHHpc+TIEdO9e3cTGBhogoODTZ8+fUxKSkpxHgYuE8nJyebhhx82VatWNb6+vqZmzZpm2LBhLo9UYszC3X766ad8f4dNSEgwxhTdGP3tt99M8+bNjd1uN5UrVzYvvfRScR1iodiMMcY9c+0AAAAAAFz6uMYbAAAAAAALEbwBAAAAALAQwRsAAAAAAAsRvAEAAAAAsBDBGwAAAAAACxG8AQAAAACwEMEbAAAAAAALEbwBAAAAALAQwRsAADfp3bu3Onfu7O4yAACAxQjeAABc4jIzM/Xhhx+qTZs2qly5siIiIhQbG6vXXntNqampefp/8803ateuncqWLSubzaZ169bl6ZOWlqYBAwaobNmyCgwM1G233aYDBw649Nm1a5c6dOggf39/VahQQY8//riysrLOWqvNZtOMGTPytPNHCgBAaUbwBgDgErZ9+3Zde+21Gjt2rG6//XZNmzZN8+fP16BBg7RgwQI1aNBAf/75p8s6J06cUPPmzfXyyy8XuN1HHnlEs2bN0rRp07Ro0SLt3btXXbp0cS7Pzs5Whw4dlJGRoaVLl+qTTz7RxIkTNXz4cMuOFQCAkorgDQC45H311VeKioqSn5+fypYtqzZt2ujEiROSpJUrV6pt27YqV66cQkJCFBcXpzVr1risb7PZNG7cOHXs2FH+/v668sortWzZMm3btk2tWrVSQECAYmNj9ddffznXee6553TNNddo3LhxioyMlL+/v7p27aqkpKQC63Q4HBo9erRq1KghPz8/XX311frqq6+cy//991/16NFD5cuXl5+fn+rUqaMJEyYUuL2kpCS1b99et956q9atW6f//ve/io2NVcOGDdW1a1fNmTNHTz31lNq1a6d///3Xud7dd9+t4cOHq02bNgVud/z48XrjjTfUunVrRUdHa8KECVq6dKmWL18uSZo/f742bdqkzz77TNdcc43i4+M1atQojR07VhkZGWf5bp3bzp07ZbPZ8ny1atXqorYLAIBVCN4AgEvavn371L17d/Xt21ebN2/WwoUL1aVLFxljJEkpKSlKSEjQkiVLtHz5ctWpU0c333yzUlJSXLYzatQo9erVS+vWrVO9evV01113qX///ho6dKhWrVolY4wefPBBl3W2bdumqVOnatasWZo7d67Wrl2rBx54oMBaR48erU8//VQffPCBNm7cqEceeUQ9e/bUokWLJEnPPPOMNm3apDlz5mjz5s16//33Va5cuQK399JLLyk6OlojR45UUlKSevTo4TzN/O2331Z8fLzuvfdetWjRQmPGjDnvz3T16tXKzMx0Ceb16tVT1apVtWzZMknSsmXLFBUVpfDwcGef9u3bKzk5WRs3bjzvfeUnMjJS+/btc36tXbtWZcuWVcuWLS9quwAAWMXL3QUAAGClffv2KSsrS126dFG1atUkSVFRUc7lrVu3dun/4YcfKjQ0VIsWLVLHjh2d7X369FHXrl0lSUOGDFFMTIyeeeYZtW/fXpL08MMPq0+fPi7bSktL06effqrKlStLkt555x116NBBr7/+uiIiIlz6pqen68UXX9QPP/ygmJgYSVLNmjW1ZMkSjRs3TnFxcdq1a5caNWqkxo0bS5KqV69+1mOfNGmS5s6dK0l69NFHtWPHDn377bc6ePCg7rvvPtWtW1dSzvXTw4YN04gRI87xaebYv3+/fHx8FBoa6tIeHh6u/fv3O/ucHrpzl+cuO5vu3bvL09PTpS09PV0dOnSQJHl6ejo/v7S0NHXu3FkxMTF67rnnzqt+AACKG8EbAHBJu/rqq3XjjTcqKipK7du3V7t27XT77berTJkykqQDBw7o6aef1sKFC3Xw4EFlZ2crNTVVu3btctlOw4YNna9zA+TpAT48PFxpaWlKTk5WcHCwJKlq1arO0C1JMTExcjgc2rJlS57gvW3bNqWmpqpt27Yu7RkZGWrUqJEk6f7779dtt92mNWvWqF27durcubNiY2PzPe6jR48qJSVFV111lSRp1qxZmjFjhpo2bSpJevDBB5WYmChJqlixosup5u725ptv5jnNfciQIcrOzs7Tt2/fvkpJSVFiYqI8PDiRDwBQMhG8AQCXNE9PTyUmJmrp0qWaP3++3nnnHQ0bNkwrVqxQjRo1lJCQoCNHjuitt95StWrVZLfbFRMTk+c6ZG9vb+drm81WYJvD4bigOo8fPy5J+u6771zCuiTZ7XZJUnx8vP7++299//33SkxM1I033qgBAwbotddey7O9rKws+fr6Ot9nZGQoICDA+T4wMND5es2aNapdu/Z51xoREaGMjAwdO3bMZdb7wIEDzj8oRERE6Ndff3VZL/eu52f+0SG/7Z9ZT1BQkI4dO+bS9vzzz2vevHn69ddfFRQUdN71AwBQ3PjTMADgkmez2dSsWTONGDFCa9eulY+Pj6ZPny5J+uWXXzRw4EDdfPPNatCggex2uw4fPlwk+921a5f27t3rfL98+XJ5eHg4T/E+Xf369WW327Vr1y7Vrl3b5SsyMtLZr3z58kpISNBnn32mMWPG6MMPP8x33+XKlVNGRoYz7DZv3lyvvPKKTp48qT179uijjz6SJC1dulTDhg3T4MGDz/u4oqOj5e3trQULFjjbtmzZol27djlPk4+JidH69et18OBBZ5/ExEQFBwerfv36572vgnz99dcaOXKkpk6dqlq1al309gAAsBIz3gCAS9qKFSu0YMECtWvXThUqVNCKFSt06NAhXXnllZKkOnXqaNKkSWrcuLGSk5P1+OOPy8/Pr0j27evrq4SEBL322mtKTk7WwIED1bVr13xnfIOCgvTYY4/pkUcekcPhUPPmzZWUlKRffvlFwcHBSkhI0PDhwxUdHa0GDRooPT1ds2fPdh7HmTw8PPSf//xH7733nkaMGKG33npLnTp1UmBgoEJCQpSQkKAxY8aob9++euutt3TjjTc61z169KjLHw22bNkiKWcmOiIiQiEhIerXr58GDx6ssLAwBQcH66GHHlJMTIyuv/56SVK7du1Uv3593X333XrllVe0f/9+Pf300xowYIBzBv9CbdiwQb169dKQIUPUoEED5zXjPj4+CgsLu6htAwBgBYI3AOCSFhwcrJ9//lljxoxRcnKyqlWrptdff13x8fGSpPHjx+u+++7Ttddeq8jISL344ot67LHHimTftWvXVpcuXXTzzTfr6NGj6tixo957770C+48aNUrly5fX6NGjtX37doWGhuraa6/VU089JSknWA4dOlQ7d+6Un5+fWrRooSlTphS4veHDh+u6667T9ddfr/j4eG3atEn79+9XmTJl5HA4NGzYsHzvij5z5kyXG8XdeeedkqRnn33WeQOzN998Ux4eHrrtttuUnp6u9u3buxybp6enZs+erfvvv18xMTEKCAhQQkKCRo4cWajPMD+rVq1Samqqnn/+eT3//PPO9ri4OC1cuPCitw8AQFGzmdznqQAAgCLz3HPPacaMGVq3bp1b65g/f77uvPNO9ezZU/fee68aNGggSVq/fr1ee+01lS9fXm+88YZbawQA4FLHNd4AAFzC2rVrp9WrVyslJUUtWrSQj4+PfHx8FB8frypVqvAILgAAigGnmgMAcImrUaOGJkyYoPHjx+vAgQPy8PDI84xtAABgHU41BwAAAADAQpxqDgAAAACAhQjeAAAAAABYiOANAAAAAICFCN4AAAAAAFiI4A0AAAAAgIUI3gAAAAAAWIjgDQAAAACAhQjeAAAAAABYiOANAAAAAICF/g9LIHyCG7+SogAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7ca640168540> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔮 Model prediction:\n",
            "  Label: Silent_MI\n",
            "  Probabilities:\n",
            "    Normal    :   0.00%\n",
            "    Silent_MI :  99.79%\n",
            "    Acute_MI  :   0.21%\n",
            "\n",
            "✅ Done.\n",
            "Submission files:\n",
            "  MAT : /content/converted/download (2)_10s_100Hz.mat\n",
            "  HEA : /content/converted/download (2)_10s_100Hz.hea\n",
            "  DAT : /content/converted/download (2)_10s_100Hz.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== ECG JPEG -> MAT + WFDB converter (+ optional model inference) ==========\n",
        "# More robust: paper-speed override, lead order remap, band-pass, telemetry & preview.\n",
        "\n",
        "import os, math, io, time, numpy as np\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "import cv2\n",
        "from skimage.morphology import skeletonize\n",
        "from scipy.signal import find_peaks, butter, filtfilt\n",
        "from scipy.io import savemat\n",
        "import matplotlib.pyplot as plt\n",
        "import wfdb\n",
        "import tensorflow as tf\n",
        "\n",
        "# ------------------ Config ------------------\n",
        "OUT_DIR = Path(\"/content/converted\"); OUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Paper/layout assumptions (tweak here)\n",
        "MM_PER_MV               = 10.0        # 10 mm = 1 mV\n",
        "PAPER_SPEED_MM_PER_SEC  = 25.0        # try 50.0 if your strip is at 50 mm/s\n",
        "TARGET_FS               = 100         # Hz\n",
        "TARGET_SECONDS          = 10.0\n",
        "TARGET_LEN              = int(TARGET_FS * TARGET_SECONDS)\n",
        "\n",
        "GRID_ROWS, GRID_COLS = 4, 3\n",
        "LEAD_NAMES = [\"I\",\"II\",\"III\",\"aVR\",\"aVL\",\"aVF\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\"]\n",
        "\n",
        "# Optional overrides / toggles\n",
        "FORCE_PX_PER_MM   = None      # e.g., 10.0 to skip auto detection\n",
        "REVERSE_POLARITY  = False     # flip sign if deflections look inverted\n",
        "USE_BANDPASS      = True      # 0.5–40 Hz after resample\n",
        "SHOW_PREVIEW      = True\n",
        "CONFIDENCE_ABSTAIN = 0.60     # if max prob < thresh: label \"Uncertain\"\n",
        "\n",
        "# If your printed page uses a different tile order, remap here:\n",
        "# tiles are [row0col0,row0col1,row0col2,row1col0,...,row3col2]\n",
        "INDEX_MAP = [0,1,2, 3,4,5, 6,7,8, 9,10,11]  # change if your panel order differs\n",
        "\n",
        "# ------------------ Helpers ------------------\n",
        "def read_image_rgb(path):\n",
        "    img = cv2.imread(str(path))\n",
        "    if img is None: raise ValueError(f\"Cannot read image: {path}\")\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "def deskew_image(img_rgb):\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(cv2.GaussianBlur(gray, (3,3), 0), 50, 120)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=180)\n",
        "    if lines is None: return img_rgb\n",
        "    angles = []\n",
        "    for rho, theta in lines[:,0,:]:\n",
        "        deg = theta*180/np.pi\n",
        "        if deg > 90: deg -= 180\n",
        "        if abs(deg) < 15 or abs(abs(deg)-90) < 15:\n",
        "            angles.append(deg)\n",
        "    if not angles: return img_rgb\n",
        "    angle = float(np.median(angles))\n",
        "    if abs(angle) < 0.5: return img_rgb\n",
        "    h,w = img_rgb.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
        "    return cv2.warpAffine(img_rgb, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "def estimate_pixels_per_mm(img_rgb):\n",
        "    if FORCE_PX_PER_MM: return float(FORCE_PX_PER_MM)\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    edges = cv2.Canny(blur, 30, 80)\n",
        "    vproj = edges.sum(axis=0); hproj = edges.sum(axis=1)\n",
        "    def _period(sig):\n",
        "        pk,_ = find_peaks(sig, distance=8, prominence=np.percentile(sig, 80))\n",
        "        if len(pk) < 5: return None\n",
        "        d = np.diff(pk)\n",
        "        return float(np.median(d)) if len(d) else None\n",
        "    pv = _period(vproj); ph = _period(hproj)\n",
        "    cands = [p for p in [pv, ph] if p and 3 <= p <= 30]\n",
        "    if not cands: return 10.0\n",
        "    period = float(np.median(cands))\n",
        "    px_per_mm = period/5.0 if period >= 14 else period\n",
        "    return float(np.clip(px_per_mm, 4.0, 16.0))\n",
        "\n",
        "def split_into_leads(img_rgb):\n",
        "    H,W = img_rgb.shape[:2]\n",
        "    tiles=[]; row_h=H//GRID_ROWS; col_w=W//GRID_COLS\n",
        "    for r in range(GRID_ROWS):\n",
        "        for c in range(GRID_COLS):\n",
        "            y0=r*row_h; y1=(r+1)*row_h if r<GRID_ROWS-1 else H\n",
        "            x0=c*col_w; x1=(c+1)*col_w if c<GRID_COLS-1 else W\n",
        "            my=int(0.08*(y1-y0)); mx=int(0.06*(x1-x0))\n",
        "            tile = img_rgb[max(0,y0+my):min(H,y1-my), max(0,x0+mx):min(W,x1-mx)]\n",
        "            tiles.append(tile)\n",
        "    # remap order if needed\n",
        "    tiles = [tiles[i] for i in INDEX_MAP]\n",
        "    return tiles\n",
        "\n",
        "def trace_signal_from_tile(tile_rgb):\n",
        "    gray = cv2.cvtColor(tile_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    norm = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    th = max(5, int(min(tile_rgb.shape[:2])*0.03) | 1)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (th, th))\n",
        "    bg = cv2.morphologyEx(norm, cv2.MORPH_OPEN, kernel)\n",
        "    fg = cv2.subtract(norm, bg)\n",
        "    _, bw = cv2.threshold(fg, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    bw = 255 - bw\n",
        "    skel = skeletonize((bw>0).astype(np.uint8) > 0)\n",
        "    H,W = skel.shape\n",
        "    y = np.full(W, np.nan, np.float32)\n",
        "    for x in range(W):\n",
        "        ys = np.where(skel[:,x])[0]\n",
        "        y[x] = np.median(ys) if ys.size else float(np.argmin(gray[:,x]))\n",
        "    if np.isnan(y).any():\n",
        "        idx = np.where(~np.isnan(y))[0]\n",
        "        if idx.size==0: raise ValueError(\"No trace found in tile.\")\n",
        "        y = np.interp(np.arange(W), idx, y[idx]).astype(np.float32)\n",
        "    return y\n",
        "\n",
        "def pixels_to_mv(y_pix, px_per_mm):\n",
        "    baseline = float(np.median(y_pix))\n",
        "    delta_pix = baseline - y_pix\n",
        "    delta_mm  = delta_pix / float(px_per_mm)\n",
        "    mv = delta_mm / MM_PER_MV\n",
        "    return (-mv if REVERSE_POLARITY else mv).astype(np.float32)\n",
        "\n",
        "def build_time_axis(n_cols, px_per_mm):\n",
        "    mm_per_col = 1.0 / float(px_per_mm)\n",
        "    sec_per_col = mm_per_col / PAPER_SPEED_MM_PER_SEC\n",
        "    return np.arange(n_cols, dtype=np.float32) * sec_per_col\n",
        "\n",
        "def resample_to_target(x_mv, t_sec, fs_target=TARGET_FS, T=TARGET_SECONDS):\n",
        "    t_uniform = np.linspace(0.0, T, int(fs_target*T), endpoint=False)\n",
        "    t_max = max(t_sec[-1], 1e-6)\n",
        "    t_clip = np.clip(t_uniform, 0.0, t_max)\n",
        "    x = np.interp(t_clip, t_sec, x_mv, left=x_mv[0], right=x_mv[-1]).astype(np.float32)\n",
        "    if USE_BANDPASS:\n",
        "        # 0.5–40 Hz band-pass, 3rd order\n",
        "        lo, hi = 0.5, 40.0\n",
        "        b,a = butter(3, [lo/(fs_target/2), hi/(fs_target/2)], btype='band')\n",
        "        # guard against all-constant input\n",
        "        if np.std(x) > 1e-6:\n",
        "            x = filtfilt(b, a, x).astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def convert_image_to_signals(img_path, out_stem=\"custom_record\"):\n",
        "    # Load + deskew\n",
        "    img0 = read_image_rgb(img_path)\n",
        "    img  = deskew_image(img0)\n",
        "\n",
        "    # Scale + tiles\n",
        "    px_per_mm = estimate_pixels_per_mm(img)\n",
        "    tiles = split_into_leads(img)\n",
        "    if len(tiles) != 12: raise ValueError(f\"Expected 12 tiles, got {len(tiles)}\")\n",
        "\n",
        "    # Trace each lead\n",
        "    signals_mv = []\n",
        "    est_durations = []\n",
        "    for tile in tiles:\n",
        "        y_pix = trace_signal_from_tile(tile)\n",
        "        mv    = pixels_to_mv(y_pix, px_per_mm)\n",
        "        tsec  = build_time_axis(len(mv), px_per_mm)\n",
        "        est_durations.append(float(tsec[-1] if len(tsec) else 0))\n",
        "        mv_rs = resample_to_target(mv, tsec, fs_target=TARGET_FS, T=TARGET_SECONDS)\n",
        "        signals_mv.append(mv_rs)\n",
        "\n",
        "    sig_mv = np.stack(signals_mv, axis=0)          # (12, T) mV\n",
        "    sig_uV = (sig_mv * 1000.0).astype(np.float32)  # µV\n",
        "    sig_uV_i16 = np.clip(sig_uV, -32768, 32767).astype(np.int16)\n",
        "\n",
        "    # Telemetry\n",
        "    print(f\"px/mm: {px_per_mm:.2f} | paper speed: {PAPER_SPEED_MM_PER_SEC} mm/s | polarity flipped: {REVERSE_POLARITY}\")\n",
        "    print(\"Estimated duration before resample (median across leads):\", f\"{np.median(est_durations):.2f} s\")\n",
        "    rng = [(float(sig_mv[i].min()), float(sig_mv[i].max())) for i in range(12)]\n",
        "    print(\"Per-lead mV ranges (min,max):\", rng)\n",
        "    print(\"Output shape (leads x samples):\", sig_mv.shape, \"(expected (12, 1000))\")\n",
        "\n",
        "    # Save MAT (PTB-XL style: 'val' in µV int16)\n",
        "    mat_path = OUT_DIR / f\"{out_stem}.mat\"\n",
        "    savemat(str(mat_path), {\"val\": sig_uV_i16})\n",
        "    print(f\"✔ Saved MAT: {mat_path}\")\n",
        "\n",
        "    # WFDB write (sanitized)\n",
        "    sig_uV_sanitized = np.nan_to_num(sig_uV, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "    sig_uV_sanitized = np.clip(sig_uV_sanitized, -1_000_000.0, 1_000_000.0)\n",
        "    wfdb.wrsamp(\n",
        "        record_name=str(out_stem),\n",
        "        fs=TARGET_FS,\n",
        "        units=[\"uV\"]*12,\n",
        "        sig_name=LEAD_NAMES,\n",
        "        p_signal=sig_uV_sanitized.T.astype(np.float64),\n",
        "        fmt=[\"32\"]*12,\n",
        "        adc_gain=[1.0]*12,\n",
        "        baseline=[0]*12,\n",
        "        write_dir=str(OUT_DIR),\n",
        "    )\n",
        "    hea_path = OUT_DIR / f\"{out_stem}.hea\"\n",
        "    dat_path = OUT_DIR / f\"{out_stem}.dat\"\n",
        "    print(f\"✔ Saved WFDB: {hea_path}, {dat_path}\")\n",
        "\n",
        "    if SHOW_PREVIEW:\n",
        "        plt.figure(figsize=(10,4))\n",
        "        for i, lead_idx in enumerate([0,1,6]):  # I, II, V1\n",
        "            plt.plot(sig_mv[lead_idx] + i*2.0, label=LEAD_NAMES[lead_idx])\n",
        "        plt.title(\"Preview (stacked offsets, mV)\"); plt.xlabel(\"Samples @100 Hz\")\n",
        "        plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    return sig_mv, str(mat_path), str(hea_path)\n",
        "\n",
        "def predict_with_trained_model(sig_mv, age_years=56, sex_str=\"male\", model_path=\"/content/silent_mi_cnn_wfdb.h5\"):\n",
        "    if not Path(model_path).exists():\n",
        "        print(\"⚠ Model not found; skipping inference.\"); return None, None\n",
        "    # per-lead z-norm (matches training)\n",
        "    sig = sig_mv.copy()\n",
        "    mu = np.median(sig, axis=1, keepdims=True)\n",
        "    sd = np.std(sig, axis=1, keepdims=True) + 1e-6\n",
        "    sig = (sig - mu) / sd\n",
        "    x_ecg = sig[np.newaxis, ..., None].astype(np.float32)\n",
        "\n",
        "    def sex_to_num(s):\n",
        "        s = str(s).strip().lower()\n",
        "        if s.startswith(\"m\"): return 1\n",
        "        if s.startswith(\"f\"): return 0\n",
        "        try: return 1 if float(s)>0.5 else 0\n",
        "        except: return 0\n",
        "    x_demo = np.array([[float(age_years), sex_to_num(sex_str)]], np.float32)\n",
        "\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    probs = model.predict({\"ecg\": x_ecg, \"demo\": x_demo}, verbose=0)[0]\n",
        "    classes = [\"Normal\",\"Silent_MI\",\"Acute_MI\"]\n",
        "    pred_idx = int(np.argmax(probs)); pred = classes[pred_idx]\n",
        "    if CONFIDENCE_ABSTAIN and float(probs[pred_idx]) < CONFIDENCE_ABSTAIN:\n",
        "        pred = \"Uncertain\"\n",
        "    return pred, {classes[i]: float(probs[i]) for i in range(3)}\n",
        "\n",
        "# ------------------ Upload & run ------------------\n",
        "print(\"📤 Upload your ECG image (jpg/png):\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded: raise SystemExit(\"No file uploaded.\")\n",
        "img_name = list(uploaded.keys())[0]\n",
        "img_path = Path(\"/content\") / img_name\n",
        "out_stem = f\"{img_path.stem}_10s_100Hz\"\n",
        "\n",
        "sig_mv, mat_path, hea_path = convert_image_to_signals(img_path, out_stem=out_stem)\n",
        "\n",
        "# Optional: predict with your trained model (if present)\n",
        "AGE = 30; SEX = \"male\"\n",
        "pred, probs = predict_with_trained_model(sig_mv, AGE, SEX, model_path=\"/content/silent_mi_cnn_wfdb.h5\")\n",
        "if pred is not None:\n",
        "    print(\"\\n🔮 Model prediction:\")\n",
        "    print(\"  Label:\", pred)\n",
        "    print(\"  Probabilities:\")\n",
        "    for k, v in probs.items(): print(f\"    {k:10s}: {v*100:6.2f}%\")\n",
        "\n",
        "print(\"\\n✅ Done.\")\n",
        "print(\"Submission files:\")\n",
        "print(\"  MAT :\", mat_path)\n",
        "print(\"  HEA :\", hea_path)\n",
        "print(\"  DAT :\", str(Path(hea_path).with_suffix('.dat')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "sj0fDCZ6udvN",
        "outputId": "6e78ec8e-5437-4c87-e657-d39d628da41f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📤 Upload your ECG image (jpg/png):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-13517aae-d9fb-4bdc-9243-7d1999009764\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-13517aae-d9fb-4bdc-9243-7d1999009764\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving normal ecgg.jpg to normal ecgg.jpg\n",
            "px/mm: 10.00 | paper speed: 25.0 mm/s | polarity flipped: False\n",
            "Estimated duration before resample (median across leads): 0.71 s\n",
            "Per-lead mV ranges (min,max): [(-0.31732648611068726, 0.15642258524894714), (-0.21128207445144653, 0.18019719421863556), (-0.2956884503364563, 0.1881283074617386), (-0.3128899931907654, 0.23576007783412933), (-0.3382832407951355, 0.2471872717142105), (-0.22058941423892975, 0.2040928602218628), (-0.3340633809566498, 0.18088732659816742), (-0.16215096414089203, 0.3164007365703583), (-0.1899704784154892, 0.22559449076652527), (-0.3340633809566498, 0.18088732659816742), (-0.7019014358520508, 0.19787341356277466), (-0.3340633809566498, 0.18088732659816742)]\n",
            "Output shape (leads x samples): (12, 1000) (expected (12, 1000))\n",
            "✔ Saved MAT: /content/converted/normal ecgg_10s_100Hz.mat\n",
            "✔ Saved WFDB: /content/converted/normal ecgg_10s_100Hz.hea, /content/converted/normal ecgg_10s_100Hz.dat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔮 Model prediction:\n",
            "  Label: Silent_MI\n",
            "  Probabilities:\n",
            "    Normal    :   0.00%\n",
            "    Silent_MI :  99.66%\n",
            "    Acute_MI  :   0.34%\n",
            "\n",
            "✅ Done.\n",
            "Submission files:\n",
            "  MAT : /content/converted/normal ecgg_10s_100Hz.mat\n",
            "  HEA : /content/converted/normal ecgg_10s_100Hz.hea\n",
            "  DAT : /content/converted/normal ecgg_10s_100Hz.dat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "41m2Sgyp4Qqf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}